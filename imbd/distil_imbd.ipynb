{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install pandas\n",
        "!pip install datasets\n",
        "!pip install transformers\n",
        "!pip install scikit-learn\n",
        "!pip install peft\n",
        "!pip install codecarbon\n",
        "!pip install matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "RdLqkl-q4-PK",
        "outputId": "60920e58-5bb4-4973-9780-712211559f3c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft) (4.50.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.5.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft) (0.5.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from peft) (0.30.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (2024.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (0.21.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2025.1.31)\n",
            "Collecting codecarbon\n",
            "  Downloading codecarbon-2.8.3-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting arrow (from codecarbon)\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from codecarbon) (8.1.8)\n",
            "Collecting fief-client[cli] (from codecarbon)\n",
            "  Downloading fief_client-0.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from codecarbon) (2.2.2)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from codecarbon) (0.21.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from codecarbon) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from codecarbon) (9.0.0)\n",
            "Requirement already satisfied: pynvml in /usr/local/lib/python3.11/dist-packages (from codecarbon) (12.0.0)\n",
            "Collecting questionary (from codecarbon)\n",
            "  Downloading questionary-2.1.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting rapidfuzz (from codecarbon)\n",
            "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from codecarbon) (2.32.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from codecarbon) (13.9.4)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.11/dist-packages (from codecarbon) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from arrow->codecarbon) (2.8.2)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow->codecarbon)\n",
            "  Downloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting httpx<0.28.0,>=0.21.3 (from fief-client[cli]->codecarbon)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jwcrypto<2.0.0,>=1.4 (from fief-client[cli]->codecarbon)\n",
            "  Downloading jwcrypto-1.5.6-py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting yaspin (from fief-client[cli]->codecarbon)\n",
            "  Downloading yaspin-3.1.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas->codecarbon) (2.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->codecarbon) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->codecarbon) (2025.2)\n",
            "Requirement already satisfied: nvidia-ml-py<13.0.0a0,>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from pynvml->codecarbon) (12.570.86)\n",
            "Requirement already satisfied: prompt_toolkit<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from questionary->codecarbon) (3.0.50)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->codecarbon) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->codecarbon) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->codecarbon) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->codecarbon) (2025.1.31)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->codecarbon) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->codecarbon) (2.18.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from typer->codecarbon) (4.13.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer->codecarbon) (1.5.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (1.0.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (0.14.0)\n",
            "Requirement already satisfied: cryptography>=3.4 in /usr/local/lib/python3.11/dist-packages (from jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (43.0.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->codecarbon) (0.1.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt_toolkit<4.0,>=2.0->questionary->codecarbon) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7.0->arrow->codecarbon) (1.17.0)\n",
            "Collecting termcolor<2.4.0,>=2.2.0 (from yaspin->fief-client[cli]->codecarbon)\n",
            "  Downloading termcolor-2.3.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=3.4->jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=3.4->jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (2.22)\n",
            "Downloading codecarbon-2.8.3-py3-none-any.whl (516 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m516.7/516.7 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading questionary-2.1.0-py3-none-any.whl (36 kB)\n",
            "Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jwcrypto-1.5.6-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.5/92.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl (14 kB)\n",
            "Downloading fief_client-0.20.0-py3-none-any.whl (20 kB)\n",
            "Downloading yaspin-3.1.0-py3-none-any.whl (18 kB)\n",
            "Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
            "Installing collected packages: types-python-dateutil, termcolor, rapidfuzz, yaspin, questionary, httpx, arrow, jwcrypto, fief-client, codecarbon\n",
            "  Attempting uninstall: termcolor\n",
            "    Found existing installation: termcolor 3.0.1\n",
            "    Uninstalling termcolor-3.0.1:\n",
            "      Successfully uninstalled termcolor-3.0.1\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-genai 1.9.0 requires httpx<1.0.0,>=0.28.1, but you have httpx 0.27.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed arrow-1.3.0 codecarbon-2.8.3 fief-client-0.20.0 httpx-0.27.2 jwcrypto-1.5.6 questionary-2.1.0 rapidfuzz-3.13.0 termcolor-2.3.0 types-python-dateutil-2.9.0.20241206 yaspin-3.1.0\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Lk-rvqk64R6j"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from datasets import DatasetDict\n",
        "from peft import get_peft_model, LoraConfig, TaskType\n",
        "from transformers import TrainerCallback\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from codecarbon import EmissionsTracker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dj-3OP84R6x",
        "outputId": "78910aef-dbdb-4729-d9e6-0559150cb222"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ClassLabel(names=['neg', 'pos'], id=None)\n"
          ]
        }
      ],
      "source": [
        "# Inspecte les étiquettes du dataset\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Charger le dataset\n",
        "dataset = load_dataset(\"imdb\")\n",
        "\n",
        "# Vérifie les étiquettes dans le dataset d'entraînement\n",
        "print(dataset['train'].features['label'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "4249c519dd9246c894c68e668b61391a",
            "d593b89e891447f9b939598b50287438",
            "6cdd845d70ee4b5790e66de5f9f74a9d",
            "00e9e5a21c6c4fb7a3101246a57b93b7",
            "a1d4fab129ff4d72aa04828f954e2910",
            "1ddb61e2427c4a3080505295668cbb10",
            "3a6f4bbb40fb41cc8e69d8db515b994b",
            "22ac7d72c47c49e98566239a0b14986a",
            "066e0ac96cd046c0b21fcef71cde1b1d",
            "a4b0318d418e4b189fd891a47ad4bae7",
            "5b8307a0df6645c2bfb2ccc89f3afc40",
            "e233da595f9949658d51c115a6e25365",
            "f9c56158a7264da5aa6af4d7b908089e",
            "b92b9daddf704c2d81c1147b08d644e7",
            "495fe494e10d49e5bb6752706531d578",
            "04742e46ed8644d4a90c8173a9eabf58",
            "a505ca059bec4c5ba1d2056d5235f4cd",
            "bb4cc9990194460e9856549974d27b43",
            "1e05b7cd331d43e385f293e1ab8d6162",
            "2f3ab07766544850a6fde2d61792aafd",
            "b473eaf60b5849bfb76b25796f6e08dc",
            "4da492780c5348cf868266154a09c44f"
          ]
        },
        "id": "JCZ1j_Q_4R62",
        "outputId": "6c74235d-39de-4d68-8f30-ea70225ec119"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/20000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4249c519dd9246c894c68e668b61391a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e233da595f9949658d51c115a6e25365"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Séparer en train et test\n",
        "split_datasets = dataset[\"train\"].train_test_split(test_size=0.2)\n",
        "\n",
        "datasets = DatasetDict({\n",
        "    \"train\": split_datasets[\"train\"],\n",
        "    \"test\": split_datasets[\"test\"],\n",
        "})\n",
        "\n",
        "# Préparer le tokenizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "# Appliquer la tokenization\n",
        "tokenized_datasets = datasets.map(tokenize_function, batched=True)\n",
        "\n",
        "# Charger le modèle pré-entraîné sans fine-tuning\n",
        "base_model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wnnMrr324R65",
        "outputId": "1d6484b1-c8d4-4292-e6cd-c0eff05733ab",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "<ipython-input-6-f13887b79c49>:75: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 739,586 || all params: 67,694,596 || trainable%: 1.0925\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "[codecarbon INFO @ 10:44:13] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 10:44:13] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 10:44:13] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n",
            "[codecarbon WARNING @ 10:44:14] We saw that you have a Intel(R) Xeon(R) CPU @ 2.30GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 10:44:14] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
            "[codecarbon INFO @ 10:44:14] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 10:44:14] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 10:44:14] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 10:44:14]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 10:44:14]   Python version: 3.11.11\n",
            "[codecarbon INFO @ 10:44:14]   CodeCarbon version: 2.8.3\n",
            "[codecarbon INFO @ 10:44:14]   Available RAM : 12.675 GB\n",
            "[codecarbon INFO @ 10:44:14]   CPU count: 2\n",
            "[codecarbon INFO @ 10:44:14]   CPU model: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
            "[codecarbon INFO @ 10:44:14]   GPU count: 1\n",
            "[codecarbon INFO @ 10:44:14]   GPU model: 1 x Tesla T4\n",
            "[codecarbon INFO @ 10:44:14] Saving emissions data to file /content/emissions.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1560' max='1560' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1560/1560 18:55, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision Global</th>\n",
              "      <th>Recall Global</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>Precision Neg</th>\n",
              "      <th>Recall Neg</th>\n",
              "      <th>F1 Neg</th>\n",
              "      <th>Precision Pos</th>\n",
              "      <th>Recall Pos</th>\n",
              "      <th>F1 Pos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.666900</td>\n",
              "      <td>0.636586</td>\n",
              "      <td>0.798000</td>\n",
              "      <td>0.798215</td>\n",
              "      <td>0.798256</td>\n",
              "      <td>0.797999</td>\n",
              "      <td>0.812348</td>\n",
              "      <td>0.784929</td>\n",
              "      <td>0.798403</td>\n",
              "      <td>0.784082</td>\n",
              "      <td>0.811582</td>\n",
              "      <td>0.797595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.317400</td>\n",
              "      <td>0.298815</td>\n",
              "      <td>0.872800</td>\n",
              "      <td>0.872753</td>\n",
              "      <td>0.872753</td>\n",
              "      <td>0.872753</td>\n",
              "      <td>0.875196</td>\n",
              "      <td>0.875196</td>\n",
              "      <td>0.875196</td>\n",
              "      <td>0.870310</td>\n",
              "      <td>0.870310</td>\n",
              "      <td>0.870310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.278600</td>\n",
              "      <td>0.264309</td>\n",
              "      <td>0.892600</td>\n",
              "      <td>0.892550</td>\n",
              "      <td>0.892672</td>\n",
              "      <td>0.892581</td>\n",
              "      <td>0.899166</td>\n",
              "      <td>0.888932</td>\n",
              "      <td>0.894020</td>\n",
              "      <td>0.885933</td>\n",
              "      <td>0.896411</td>\n",
              "      <td>0.891141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.258700</td>\n",
              "      <td>0.243369</td>\n",
              "      <td>0.902600</td>\n",
              "      <td>0.902561</td>\n",
              "      <td>0.902699</td>\n",
              "      <td>0.902586</td>\n",
              "      <td>0.910068</td>\n",
              "      <td>0.897567</td>\n",
              "      <td>0.903774</td>\n",
              "      <td>0.895054</td>\n",
              "      <td>0.907830</td>\n",
              "      <td>0.901397</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 10:44:29] Energy consumed for RAM : 0.000020 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:44:29] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:44:29] Energy consumed for all GPUs : 0.000272 kWh. Total GPU Power : 65.21620481121546 W\n",
            "[codecarbon INFO @ 10:44:29] 0.000469 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:44:44] Energy consumed for RAM : 0.000040 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:44:44] Energy consumed for all CPUs : 0.000354 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:44:44] Energy consumed for all GPUs : 0.000558 kWh. Total GPU Power : 68.67571407656136 W\n",
            "[codecarbon INFO @ 10:44:44] 0.000952 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:44:59] Energy consumed for RAM : 0.000059 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:44:59] Energy consumed for all CPUs : 0.000531 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:44:59] Energy consumed for all GPUs : 0.000845 kWh. Total GPU Power : 68.75406062642043 W\n",
            "[codecarbon INFO @ 10:44:59] 0.001435 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:45:14] Energy consumed for RAM : 0.000079 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:45:14] Energy consumed for all CPUs : 0.000708 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:45:14] Energy consumed for all GPUs : 0.001129 kWh. Total GPU Power : 68.26536554078922 W\n",
            "[codecarbon INFO @ 10:45:14] 0.001916 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:45:29] Energy consumed for RAM : 0.000099 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:45:29] Energy consumed for all CPUs : 0.000885 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:45:29] Energy consumed for all GPUs : 0.001416 kWh. Total GPU Power : 68.88304010237697 W\n",
            "[codecarbon INFO @ 10:45:29] 0.002400 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:45:44] Energy consumed for RAM : 0.000119 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:45:44] Energy consumed for all CPUs : 0.001062 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:45:44] Energy consumed for all GPUs : 0.001698 kWh. Total GPU Power : 67.73899812675664 W\n",
            "[codecarbon INFO @ 10:45:44] 0.002879 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:45:59] Energy consumed for RAM : 0.000139 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:45:59] Energy consumed for all CPUs : 0.001239 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:45:59] Energy consumed for all GPUs : 0.001985 kWh. Total GPU Power : 68.79453599466744 W\n",
            "[codecarbon INFO @ 10:45:59] 0.003363 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:46:14] Energy consumed for RAM : 0.000158 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:46:14] Energy consumed for all CPUs : 0.001416 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:46:14] Energy consumed for all GPUs : 0.002273 kWh. Total GPU Power : 69.3421489344829 W\n",
            "[codecarbon INFO @ 10:46:14] 0.003848 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:46:14] 0.009152 g.CO2eq/s mean an estimation of 288.62666941721835 kg.CO2eq/year\n",
            "[codecarbon INFO @ 10:46:29] Energy consumed for RAM : 0.000178 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:46:29] Energy consumed for all CPUs : 0.001593 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:46:29] Energy consumed for all GPUs : 0.002560 kWh. Total GPU Power : 68.70705218844522 W\n",
            "[codecarbon INFO @ 10:46:29] 0.004331 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:46:44] Energy consumed for RAM : 0.000198 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:46:44] Energy consumed for all CPUs : 0.001771 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:46:44] Energy consumed for all GPUs : 0.002845 kWh. Total GPU Power : 68.35358347933936 W\n",
            "[codecarbon INFO @ 10:46:44] 0.004813 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:46:59] Energy consumed for RAM : 0.000218 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:46:59] Energy consumed for all CPUs : 0.001948 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:46:59] Energy consumed for all GPUs : 0.003133 kWh. Total GPU Power : 69.1339562954719 W\n",
            "[codecarbon INFO @ 10:46:59] 0.005298 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:47:14] Energy consumed for RAM : 0.000238 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:47:14] Energy consumed for all CPUs : 0.002125 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:47:14] Energy consumed for all GPUs : 0.003419 kWh. Total GPU Power : 68.72649899411921 W\n",
            "[codecarbon INFO @ 10:47:14] 0.005781 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:47:29] Energy consumed for RAM : 0.000257 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:47:29] Energy consumed for all CPUs : 0.002302 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:47:29] Energy consumed for all GPUs : 0.003699 kWh. Total GPU Power : 67.23020992829125 W\n",
            "[codecarbon INFO @ 10:47:29] 0.006258 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:47:44] Energy consumed for RAM : 0.000277 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:47:44] Energy consumed for all CPUs : 0.002479 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:47:44] Energy consumed for all GPUs : 0.003987 kWh. Total GPU Power : 69.11276223498535 W\n",
            "[codecarbon INFO @ 10:47:44] 0.006743 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:47:59] Energy consumed for RAM : 0.000297 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:47:59] Energy consumed for all CPUs : 0.002656 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:47:59] Energy consumed for all GPUs : 0.004271 kWh. Total GPU Power : 68.1898902082806 W\n",
            "[codecarbon INFO @ 10:47:59] 0.007224 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:48:14] Energy consumed for RAM : 0.000317 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:48:14] Energy consumed for all CPUs : 0.002833 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:48:14] Energy consumed for all GPUs : 0.004559 kWh. Total GPU Power : 69.12738786164999 W\n",
            "[codecarbon INFO @ 10:48:14] 0.007709 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:48:14] 0.009180 g.CO2eq/s mean an estimation of 289.48864796254816 kg.CO2eq/year\n",
            "[codecarbon INFO @ 10:48:29] Energy consumed for RAM : 0.000337 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:48:29] Energy consumed for all CPUs : 0.003010 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:48:29] Energy consumed for all GPUs : 0.004845 kWh. Total GPU Power : 68.676221661381 W\n",
            "[codecarbon INFO @ 10:48:29] 0.008192 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:48:44] Energy consumed for RAM : 0.000356 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:48:44] Energy consumed for all CPUs : 0.003187 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:48:44] Energy consumed for all GPUs : 0.005129 kWh. Total GPU Power : 68.1288071434012 W\n",
            "[codecarbon INFO @ 10:48:44] 0.008672 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:48:59] Energy consumed for RAM : 0.000376 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:48:59] Energy consumed for all CPUs : 0.003364 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:48:59] Energy consumed for all GPUs : 0.005415 kWh. Total GPU Power : 68.78623812531316 W\n",
            "[codecarbon INFO @ 10:48:59] 0.009155 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:49:14] Energy consumed for RAM : 0.000396 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:49:14] Energy consumed for all CPUs : 0.003541 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:49:14] Energy consumed for all GPUs : 0.005701 kWh. Total GPU Power : 68.64979193721686 W\n",
            "[codecarbon INFO @ 10:49:14] 0.009638 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:49:29] Energy consumed for RAM : 0.000416 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:49:29] Energy consumed for all CPUs : 0.003718 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:49:29] Energy consumed for all GPUs : 0.005988 kWh. Total GPU Power : 68.86351868865961 W\n",
            "[codecarbon INFO @ 10:49:29] 0.010122 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:49:44] Energy consumed for RAM : 0.000436 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:49:44] Energy consumed for all CPUs : 0.003895 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:49:44] Energy consumed for all GPUs : 0.006274 kWh. Total GPU Power : 68.51512274391894 W\n",
            "[codecarbon INFO @ 10:49:44] 0.010605 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:49:59] Energy consumed for RAM : 0.000455 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:49:59] Energy consumed for all CPUs : 0.004072 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:49:59] Energy consumed for all GPUs : 0.006562 kWh. Total GPU Power : 69.099304931402 W\n",
            "[codecarbon INFO @ 10:49:59] 0.011090 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:50:14] Energy consumed for RAM : 0.000475 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:50:14] Energy consumed for all CPUs : 0.004249 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:50:14] Energy consumed for all GPUs : 0.006848 kWh. Total GPU Power : 68.67976661396503 W\n",
            "[codecarbon INFO @ 10:50:14] 0.011572 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:50:14] 0.009189 g.CO2eq/s mean an estimation of 289.7960308262659 kg.CO2eq/year\n",
            "[codecarbon INFO @ 10:50:29] Energy consumed for RAM : 0.000495 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:50:29] Energy consumed for all CPUs : 0.004426 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:50:29] Energy consumed for all GPUs : 0.007132 kWh. Total GPU Power : 68.16461939304494 W\n",
            "[codecarbon INFO @ 10:50:29] 0.012054 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:50:44] Energy consumed for RAM : 0.000515 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:50:44] Energy consumed for all CPUs : 0.004604 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:50:44] Energy consumed for all GPUs : 0.007411 kWh. Total GPU Power : 66.79085693074228 W\n",
            "[codecarbon INFO @ 10:50:44] 0.012529 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:50:59] Energy consumed for RAM : 0.000535 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:50:59] Energy consumed for all CPUs : 0.004781 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:50:59] Energy consumed for all GPUs : 0.007694 kWh. Total GPU Power : 67.84961064720515 W\n",
            "[codecarbon INFO @ 10:50:59] 0.013009 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:51:14] Energy consumed for RAM : 0.000554 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:51:14] Energy consumed for all CPUs : 0.004958 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:51:14] Energy consumed for all GPUs : 0.007974 kWh. Total GPU Power : 67.34558155384981 W\n",
            "[codecarbon INFO @ 10:51:14] 0.013486 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:51:29] Energy consumed for RAM : 0.000574 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:51:29] Energy consumed for all CPUs : 0.005135 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:51:29] Energy consumed for all GPUs : 0.008253 kWh. Total GPU Power : 66.79419373594604 W\n",
            "[codecarbon INFO @ 10:51:29] 0.013962 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:51:44] Energy consumed for RAM : 0.000594 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:51:44] Energy consumed for all CPUs : 0.005312 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:51:44] Energy consumed for all GPUs : 0.008518 kWh. Total GPU Power : 63.693274241713894 W\n",
            "[codecarbon INFO @ 10:51:44] 0.014424 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:51:59] Energy consumed for RAM : 0.000614 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:51:59] Energy consumed for all CPUs : 0.005489 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:51:59] Energy consumed for all GPUs : 0.008796 kWh. Total GPU Power : 66.969611019418 W\n",
            "[codecarbon INFO @ 10:51:59] 0.014899 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:52:14] Energy consumed for RAM : 0.000634 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:52:14] Energy consumed for all CPUs : 0.005666 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:52:14] Energy consumed for all GPUs : 0.009082 kWh. Total GPU Power : 68.66559288493998 W\n",
            "[codecarbon INFO @ 10:52:14] 0.015382 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:52:14] 0.009056 g.CO2eq/s mean an estimation of 285.60391455601075 kg.CO2eq/year\n",
            "[codecarbon INFO @ 10:52:29] Energy consumed for RAM : 0.000653 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:52:29] Energy consumed for all CPUs : 0.005843 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:52:29] Energy consumed for all GPUs : 0.009365 kWh. Total GPU Power : 67.67649127406595 W\n",
            "[codecarbon INFO @ 10:52:29] 0.015861 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:52:44] Energy consumed for RAM : 0.000673 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:52:44] Energy consumed for all CPUs : 0.006020 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:52:44] Energy consumed for all GPUs : 0.009646 kWh. Total GPU Power : 67.4075441479341 W\n",
            "[codecarbon INFO @ 10:52:44] 0.016339 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:52:59] Energy consumed for RAM : 0.000693 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:52:59] Energy consumed for all CPUs : 0.006197 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:52:59] Energy consumed for all GPUs : 0.009931 kWh. Total GPU Power : 68.54538020682136 W\n",
            "[codecarbon INFO @ 10:52:59] 0.016821 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:53:14] Energy consumed for RAM : 0.000713 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:53:14] Energy consumed for all CPUs : 0.006374 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:53:14] Energy consumed for all GPUs : 0.010219 kWh. Total GPU Power : 69.0649605787866 W\n",
            "[codecarbon INFO @ 10:53:14] 0.017305 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:53:29] Energy consumed for RAM : 0.000732 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:53:29] Energy consumed for all CPUs : 0.006551 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:53:29] Energy consumed for all GPUs : 0.010503 kWh. Total GPU Power : 68.29136574015492 W\n",
            "[codecarbon INFO @ 10:53:29] 0.017786 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:53:44] Energy consumed for RAM : 0.000752 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:53:44] Energy consumed for all CPUs : 0.006728 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:53:44] Energy consumed for all GPUs : 0.010782 kWh. Total GPU Power : 66.85108349739 W\n",
            "[codecarbon INFO @ 10:53:44] 0.018262 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:53:59] Energy consumed for RAM : 0.000772 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:53:59] Energy consumed for all CPUs : 0.006905 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:53:59] Energy consumed for all GPUs : 0.011070 kWh. Total GPU Power : 69.15404520425638 W\n",
            "[codecarbon INFO @ 10:53:59] 0.018747 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:54:14] Energy consumed for RAM : 0.000792 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:54:14] Energy consumed for all CPUs : 0.007082 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:54:14] Energy consumed for all GPUs : 0.011354 kWh. Total GPU Power : 68.31400723220831 W\n",
            "[codecarbon INFO @ 10:54:14] 0.019228 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:54:14] 0.009147 g.CO2eq/s mean an estimation of 288.46058629934254 kg.CO2eq/year\n",
            "[codecarbon INFO @ 10:54:29] Energy consumed for RAM : 0.000812 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:54:29] Energy consumed for all CPUs : 0.007259 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:54:29] Energy consumed for all GPUs : 0.011641 kWh. Total GPU Power : 68.68053978574359 W\n",
            "[codecarbon INFO @ 10:54:29] 0.019712 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:54:44] Energy consumed for RAM : 0.000831 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:54:44] Energy consumed for all CPUs : 0.007436 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:54:44] Energy consumed for all GPUs : 0.011928 kWh. Total GPU Power : 69.0729450491129 W\n",
            "[codecarbon INFO @ 10:54:44] 0.020196 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:54:59] Energy consumed for RAM : 0.000851 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:54:59] Energy consumed for all CPUs : 0.007613 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:54:59] Energy consumed for all GPUs : 0.012215 kWh. Total GPU Power : 68.70714712703807 W\n",
            "[codecarbon INFO @ 10:54:59] 0.020680 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:55:14] Energy consumed for RAM : 0.000871 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:55:14] Energy consumed for all CPUs : 0.007791 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:55:14] Energy consumed for all GPUs : 0.012500 kWh. Total GPU Power : 68.48770033784803 W\n",
            "[codecarbon INFO @ 10:55:14] 0.021162 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:55:29] Energy consumed for RAM : 0.000891 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:55:29] Energy consumed for all CPUs : 0.007968 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:55:29] Energy consumed for all GPUs : 0.012784 kWh. Total GPU Power : 68.11770153160732 W\n",
            "[codecarbon INFO @ 10:55:29] 0.021643 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:55:44] Energy consumed for RAM : 0.000911 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:55:44] Energy consumed for all CPUs : 0.008145 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:55:44] Energy consumed for all GPUs : 0.013069 kWh. Total GPU Power : 68.46674724854927 W\n",
            "[codecarbon INFO @ 10:55:44] 0.022125 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:55:59] Energy consumed for RAM : 0.000931 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:55:59] Energy consumed for all CPUs : 0.008322 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:55:59] Energy consumed for all GPUs : 0.013356 kWh. Total GPU Power : 68.71938312512016 W\n",
            "[codecarbon INFO @ 10:55:59] 0.022608 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:56:14] Energy consumed for RAM : 0.000950 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:56:14] Energy consumed for all CPUs : 0.008499 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:56:14] Energy consumed for all GPUs : 0.013644 kWh. Total GPU Power : 69.1740368350141 W\n",
            "[codecarbon INFO @ 10:56:14] 0.023093 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:56:14] 0.009189 g.CO2eq/s mean an estimation of 289.7784088734039 kg.CO2eq/year\n",
            "[codecarbon INFO @ 10:56:29] Energy consumed for RAM : 0.000970 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:56:29] Energy consumed for all CPUs : 0.008676 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:56:29] Energy consumed for all GPUs : 0.013930 kWh. Total GPU Power : 68.68211655167856 W\n",
            "[codecarbon INFO @ 10:56:29] 0.023576 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:56:44] Energy consumed for RAM : 0.000990 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:56:44] Energy consumed for all CPUs : 0.008853 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:56:44] Energy consumed for all GPUs : 0.014216 kWh. Total GPU Power : 68.61897001914528 W\n",
            "[codecarbon INFO @ 10:56:44] 0.024058 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:56:59] Energy consumed for RAM : 0.001010 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:56:59] Energy consumed for all CPUs : 0.009030 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:56:59] Energy consumed for all GPUs : 0.014503 kWh. Total GPU Power : 69.0725019502416 W\n",
            "[codecarbon INFO @ 10:56:59] 0.024543 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:57:14] Energy consumed for RAM : 0.001029 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:57:14] Energy consumed for all CPUs : 0.009207 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:57:14] Energy consumed for all GPUs : 0.014789 kWh. Total GPU Power : 68.68519726671737 W\n",
            "[codecarbon INFO @ 10:57:14] 0.025026 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:57:29] Energy consumed for RAM : 0.001049 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:57:29] Energy consumed for all CPUs : 0.009384 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:57:29] Energy consumed for all GPUs : 0.015076 kWh. Total GPU Power : 68.72905499153958 W\n",
            "[codecarbon INFO @ 10:57:29] 0.025509 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:57:44] Energy consumed for RAM : 0.001069 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:57:44] Energy consumed for all CPUs : 0.009561 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:57:44] Energy consumed for all GPUs : 0.015362 kWh. Total GPU Power : 68.64799456775954 W\n",
            "[codecarbon INFO @ 10:57:44] 0.025991 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:57:59] Energy consumed for RAM : 0.001089 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:57:59] Energy consumed for all CPUs : 0.009738 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:57:59] Energy consumed for all GPUs : 0.015643 kWh. Total GPU Power : 67.45413054052528 W\n",
            "[codecarbon INFO @ 10:57:59] 0.026469 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:58:14] Energy consumed for RAM : 0.001109 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:58:14] Energy consumed for all CPUs : 0.009915 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:58:14] Energy consumed for all GPUs : 0.015920 kWh. Total GPU Power : 66.39450592954798 W\n",
            "[codecarbon INFO @ 10:58:14] 0.026943 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:58:14] 0.009158 g.CO2eq/s mean an estimation of 288.81404973360463 kg.CO2eq/year\n",
            "[codecarbon INFO @ 10:58:29] Energy consumed for RAM : 0.001128 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:58:29] Energy consumed for all CPUs : 0.010092 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:58:29] Energy consumed for all GPUs : 0.016205 kWh. Total GPU Power : 68.48007979558088 W\n",
            "[codecarbon INFO @ 10:58:29] 0.027426 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:58:44] Energy consumed for RAM : 0.001148 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:58:44] Energy consumed for all CPUs : 0.010269 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:58:44] Energy consumed for all GPUs : 0.016491 kWh. Total GPU Power : 68.65974189498347 W\n",
            "[codecarbon INFO @ 10:58:44] 0.027908 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:58:59] Energy consumed for RAM : 0.001168 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:58:59] Energy consumed for all CPUs : 0.010446 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:58:59] Energy consumed for all GPUs : 0.016777 kWh. Total GPU Power : 68.63370469699106 W\n",
            "[codecarbon INFO @ 10:58:59] 0.028391 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:59:14] Energy consumed for RAM : 0.001188 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:59:14] Energy consumed for all CPUs : 0.010623 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:59:14] Energy consumed for all GPUs : 0.017064 kWh. Total GPU Power : 68.95015523744395 W\n",
            "[codecarbon INFO @ 10:59:14] 0.028875 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:59:29] Energy consumed for RAM : 0.001208 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:59:29] Energy consumed for all CPUs : 0.010800 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:59:29] Energy consumed for all GPUs : 0.017350 kWh. Total GPU Power : 68.5914219990322 W\n",
            "[codecarbon INFO @ 10:59:29] 0.029357 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:59:44] Energy consumed for RAM : 0.001227 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:59:44] Energy consumed for all CPUs : 0.010977 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:59:44] Energy consumed for all GPUs : 0.017636 kWh. Total GPU Power : 68.62711173740068 W\n",
            "[codecarbon INFO @ 10:59:44] 0.029840 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 10:59:59] Energy consumed for RAM : 0.001247 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 10:59:59] Energy consumed for all CPUs : 0.011154 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 10:59:59] Energy consumed for all GPUs : 0.017923 kWh. Total GPU Power : 69.04759526894132 W\n",
            "[codecarbon INFO @ 10:59:59] 0.030325 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:00:14] Energy consumed for RAM : 0.001267 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:00:14] Energy consumed for all CPUs : 0.011331 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:00:14] Energy consumed for all GPUs : 0.018209 kWh. Total GPU Power : 68.42728738030503 W\n",
            "[codecarbon INFO @ 11:00:14] 0.030807 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:00:14] 0.009188 g.CO2eq/s mean an estimation of 289.7401051231618 kg.CO2eq/year\n",
            "[codecarbon INFO @ 11:00:29] Energy consumed for RAM : 0.001287 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:00:29] Energy consumed for all CPUs : 0.011508 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:00:29] Energy consumed for all GPUs : 0.018495 kWh. Total GPU Power : 68.76816564197398 W\n",
            "[codecarbon INFO @ 11:00:29] 0.031290 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:00:44] Energy consumed for RAM : 0.001307 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:00:44] Energy consumed for all CPUs : 0.011685 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:00:44] Energy consumed for all GPUs : 0.018783 kWh. Total GPU Power : 69.19979211741575 W\n",
            "[codecarbon INFO @ 11:00:44] 0.031775 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:00:59] Energy consumed for RAM : 0.001326 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:00:59] Energy consumed for all CPUs : 0.011862 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:00:59] Energy consumed for all GPUs : 0.019069 kWh. Total GPU Power : 68.56541788972277 W\n",
            "[codecarbon INFO @ 11:00:59] 0.032258 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:01:14] Energy consumed for RAM : 0.001346 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:01:14] Energy consumed for all CPUs : 0.012040 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:01:14] Energy consumed for all GPUs : 0.019355 kWh. Total GPU Power : 68.5577834912152 W\n",
            "[codecarbon INFO @ 11:01:14] 0.032740 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:01:29] Energy consumed for RAM : 0.001366 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:01:29] Energy consumed for all CPUs : 0.012216 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:01:29] Energy consumed for all GPUs : 0.019643 kWh. Total GPU Power : 69.18031358193834 W\n",
            "[codecarbon INFO @ 11:01:29] 0.033225 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:01:44] Energy consumed for RAM : 0.001386 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:01:44] Energy consumed for all CPUs : 0.012393 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:01:44] Energy consumed for all GPUs : 0.019929 kWh. Total GPU Power : 68.65938533143769 W\n",
            "[codecarbon INFO @ 11:01:44] 0.033708 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:01:59] Energy consumed for RAM : 0.001406 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:01:59] Energy consumed for all CPUs : 0.012570 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:01:59] Energy consumed for all GPUs : 0.020215 kWh. Total GPU Power : 68.69484885845125 W\n",
            "[codecarbon INFO @ 11:01:59] 0.034191 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:02:14] Energy consumed for RAM : 0.001425 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:02:14] Energy consumed for all CPUs : 0.012747 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:02:14] Energy consumed for all GPUs : 0.020500 kWh. Total GPU Power : 68.57338018054287 W\n",
            "[codecarbon INFO @ 11:02:14] 0.034673 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:02:14] 0.009196 g.CO2eq/s mean an estimation of 290.0199246581221 kg.CO2eq/year\n",
            "[codecarbon INFO @ 11:02:29] Energy consumed for RAM : 0.001445 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:02:29] Energy consumed for all CPUs : 0.012924 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:02:29] Energy consumed for all GPUs : 0.020788 kWh. Total GPU Power : 69.03472826869772 W\n",
            "[codecarbon INFO @ 11:02:29] 0.035158 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:02:44] Energy consumed for RAM : 0.001465 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:02:44] Energy consumed for all CPUs : 0.013101 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:02:44] Energy consumed for all GPUs : 0.021074 kWh. Total GPU Power : 68.80453055776194 W\n",
            "[codecarbon INFO @ 11:02:44] 0.035641 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:02:59] Energy consumed for RAM : 0.001485 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:02:59] Energy consumed for all CPUs : 0.013278 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:02:59] Energy consumed for all GPUs : 0.021361 kWh. Total GPU Power : 68.88266553390764 W\n",
            "[codecarbon INFO @ 11:02:59] 0.036124 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:03:11] Energy consumed for RAM : 0.001500 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:03:11] Energy consumed for all CPUs : 0.013415 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:03:11] Energy consumed for all GPUs : 0.021582 kWh. Total GPU Power : 68.59813639773905 W\n",
            "[codecarbon INFO @ 11:03:11] 0.036497 kWh of electricity used since the beginning.\n",
            "/usr/local/lib/python3.11/dist-packages/codecarbon/output_methods/file.py:52: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df = pd.concat([df, pd.DataFrame.from_records([dict(total.values)])])\n"
          ]
        }
      ],
      "source": [
        "# Récupérer les noms des classes directement à partir du dataset\n",
        "class_names = dataset['train'].features['label'].names\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = torch.argmax(torch.tensor(logits), dim=-1)\n",
        "\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=None, zero_division=1)\n",
        "\n",
        "    # Calcul des métriques globales (moyenne des classes)\n",
        "    precision_global = precision.mean()\n",
        "    recall_global = recall.mean()\n",
        "    f1_macro = f1.mean()  # Ajout du F1-score macro\n",
        "\n",
        "    metrics = {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision_global\": precision_global,\n",
        "        \"recall_global\": recall_global,\n",
        "        \"f1_macro\": f1_macro\n",
        "    }\n",
        "\n",
        "    # Ajouter les métriques par classe avec les noms explicites\n",
        "    for i, (p, r, f) in enumerate(zip(precision, recall, f1)):\n",
        "        metrics[f\"precision_{class_names[i]}\"] = p\n",
        "        metrics[f\"recall_{class_names[i]}\"] = r\n",
        "        metrics[f\"f1_{class_names[i]}\"] = f\n",
        "\n",
        "    return metrics\n",
        "\n",
        "# Configurer LoRA\n",
        "lora_config = LoraConfig(\n",
        "    task_type=TaskType.SEQ_CLS,  # Classification de séquence\n",
        "    r=8,  # Rang de la décomposition\n",
        "    lora_alpha=16,  # Facteur d'adaptation\n",
        "    lora_dropout=0.1,  # Dropout pour LoRA\n",
        "    target_modules=[\"q_lin\", \"v_lin\"]  # Modules spécifiques à LoRA dans les transformers\n",
        ")\n",
        "\n",
        "# Appliquer LoRA au modèle\n",
        "model = get_peft_model(base_model, lora_config)\n",
        "model.print_trainable_parameters()\n",
        "\n",
        "# Configurer l'entraînement avec fine-tuning LoRA\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results_lora\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=100,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    gradient_accumulation_steps=2,\n",
        "    num_train_epochs=5,\n",
        "    learning_rate=3e-5,\n",
        "    weight_decay=0.05,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    warmup_steps=1000,\n",
        "    max_grad_norm=0.8,\n",
        "    metric_for_best_model=\"f1_macro\",\n",
        "    seed=123,\n",
        "    fp16=True,\n",
        "    report_to=\"none\",\n",
        "    overwrite_output_dir=True,\n",
        "    disable_tqdm=False,\n",
        "    logging_first_step=True,\n",
        ")\n",
        "\n",
        "\n",
        "small_train_dataset = tokenized_datasets[\"train\"]\n",
        "small_test_dataset = tokenized_datasets[\"test\"]\n",
        "\n",
        "# Initialisation du Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=small_train_dataset,  # Dataset d'entraînement\n",
        "    eval_dataset=small_test_dataset,  # Dataset de test\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "tracker = EmissionsTracker()\n",
        "tracker.start()\n",
        "\n",
        "train_result = trainer.train()\n",
        "\n",
        "emissions = tracker.stop()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from codecarbon import EmissionsTracker\n",
        "\n",
        "# Charger le modèle de base\n",
        "base_model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=4)\n",
        "\n",
        "# ✅ CHOIX : Sélectionner les paramètres à entraîner\n",
        "freeze_mode = \"last_layers\"  # \"head\", \"last_layers\", \"embeddings\", \"none\"\n",
        "\n",
        "if freeze_mode == \"head\":\n",
        "    for param in base_model.distilbert.parameters():\n",
        "        param.requires_grad = False  # Gèle tout sauf la tête\n",
        "\n",
        "elif freeze_mode == \"last_layers\":\n",
        "    for param in base_model.distilbert.parameters():\n",
        "        param.requires_grad = False  # Gèle tout\n",
        "    for layer in base_model.distilbert.transformer.layer[-2:]:  # Dégeler les 2 dernières couches\n",
        "        for param in layer.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "elif freeze_mode == \"embeddings\":\n",
        "    for param in base_model.distilbert.embeddings.parameters():\n",
        "        param.requires_grad = False  # Gèle uniquement les embeddings\n",
        "\n",
        "elif freeze_mode == \"none\":\n",
        "    pass  # Fine-tune complet\n",
        "\n",
        "# Vérifier les paramètres entraînables\n",
        "for name, param in base_model.named_parameters():\n",
        "    print(f\"{name}: requires_grad = {param.requires_grad}\")\n",
        "\n",
        "# Fonction de calcul des métriques\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = torch.argmax(torch.tensor(logits), dim=-1)\n",
        "\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=None, zero_division=1)\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision_global\": precision.mean(),\n",
        "        \"recall_global\": recall.mean(),\n",
        "        \"f1_macro\": f1.mean()\n",
        "    }\n",
        "\n",
        "# Arguments d'entraînement\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results_sans_lora\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"no\",\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=100,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    gradient_accumulation_steps=2,\n",
        "    num_train_epochs=5,\n",
        "    learning_rate=3e-5,\n",
        "    weight_decay=0.05,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    warmup_steps=1000,\n",
        "    max_grad_norm=0.8,\n",
        "    metric_for_best_model=\"f1_macro\",\n",
        "    seed=123,\n",
        "    fp16=True,\n",
        "    report_to=\"none\",\n",
        "    overwrite_output_dir=True,\n",
        "    disable_tqdm=False,\n",
        "    logging_first_step=True,\n",
        ")\n",
        "\n",
        "# Initialisation du Trainer\n",
        "trainer = Trainer(\n",
        "    model=base_model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Suivi de l'empreinte carbone\n",
        "tracker = EmissionsTracker()\n",
        "tracker.start()\n",
        "\n",
        "# Entraînement\n",
        "train_result = trainer.train()\n",
        "\n",
        "# Fin du suivi carbone\n",
        "emissions = tracker.stop()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4F1Qr98AwP1R",
        "outputId": "79c76792-deaf-40b5-aa66-1be445ea038a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "<ipython-input-4-867365aa5765>:76: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "distilbert.embeddings.word_embeddings.weight: requires_grad = False\n",
            "distilbert.embeddings.position_embeddings.weight: requires_grad = False\n",
            "distilbert.embeddings.LayerNorm.weight: requires_grad = False\n",
            "distilbert.embeddings.LayerNorm.bias: requires_grad = False\n",
            "distilbert.transformer.layer.0.attention.q_lin.weight: requires_grad = False\n",
            "distilbert.transformer.layer.0.attention.q_lin.bias: requires_grad = False\n",
            "distilbert.transformer.layer.0.attention.k_lin.weight: requires_grad = False\n",
            "distilbert.transformer.layer.0.attention.k_lin.bias: requires_grad = False\n",
            "distilbert.transformer.layer.0.attention.v_lin.weight: requires_grad = False\n",
            "distilbert.transformer.layer.0.attention.v_lin.bias: requires_grad = False\n",
            "distilbert.transformer.layer.0.attention.out_lin.weight: requires_grad = False\n",
            "distilbert.transformer.layer.0.attention.out_lin.bias: requires_grad = False\n",
            "distilbert.transformer.layer.0.sa_layer_norm.weight: requires_grad = False\n",
            "distilbert.transformer.layer.0.sa_layer_norm.bias: requires_grad = False\n",
            "distilbert.transformer.layer.0.ffn.lin1.weight: requires_grad = False\n",
            "distilbert.transformer.layer.0.ffn.lin1.bias: requires_grad = False\n",
            "distilbert.transformer.layer.0.ffn.lin2.weight: requires_grad = False\n",
            "distilbert.transformer.layer.0.ffn.lin2.bias: requires_grad = False\n",
            "distilbert.transformer.layer.0.output_layer_norm.weight: requires_grad = False\n",
            "distilbert.transformer.layer.0.output_layer_norm.bias: requires_grad = False\n",
            "distilbert.transformer.layer.1.attention.q_lin.weight: requires_grad = False\n",
            "distilbert.transformer.layer.1.attention.q_lin.bias: requires_grad = False\n",
            "distilbert.transformer.layer.1.attention.k_lin.weight: requires_grad = False\n",
            "distilbert.transformer.layer.1.attention.k_lin.bias: requires_grad = False\n",
            "distilbert.transformer.layer.1.attention.v_lin.weight: requires_grad = False\n",
            "distilbert.transformer.layer.1.attention.v_lin.bias: requires_grad = False\n",
            "distilbert.transformer.layer.1.attention.out_lin.weight: requires_grad = False\n",
            "distilbert.transformer.layer.1.attention.out_lin.bias: requires_grad = False\n",
            "distilbert.transformer.layer.1.sa_layer_norm.weight: requires_grad = False\n",
            "distilbert.transformer.layer.1.sa_layer_norm.bias: requires_grad = False\n",
            "distilbert.transformer.layer.1.ffn.lin1.weight: requires_grad = False\n",
            "distilbert.transformer.layer.1.ffn.lin1.bias: requires_grad = False\n",
            "distilbert.transformer.layer.1.ffn.lin2.weight: requires_grad = False\n",
            "distilbert.transformer.layer.1.ffn.lin2.bias: requires_grad = False\n",
            "distilbert.transformer.layer.1.output_layer_norm.weight: requires_grad = False\n",
            "distilbert.transformer.layer.1.output_layer_norm.bias: requires_grad = False\n",
            "distilbert.transformer.layer.2.attention.q_lin.weight: requires_grad = False\n",
            "distilbert.transformer.layer.2.attention.q_lin.bias: requires_grad = False\n",
            "distilbert.transformer.layer.2.attention.k_lin.weight: requires_grad = False\n",
            "distilbert.transformer.layer.2.attention.k_lin.bias: requires_grad = False\n",
            "distilbert.transformer.layer.2.attention.v_lin.weight: requires_grad = False\n",
            "distilbert.transformer.layer.2.attention.v_lin.bias: requires_grad = False\n",
            "distilbert.transformer.layer.2.attention.out_lin.weight: requires_grad = False\n",
            "distilbert.transformer.layer.2.attention.out_lin.bias: requires_grad = False\n",
            "distilbert.transformer.layer.2.sa_layer_norm.weight: requires_grad = False\n",
            "distilbert.transformer.layer.2.sa_layer_norm.bias: requires_grad = False\n",
            "distilbert.transformer.layer.2.ffn.lin1.weight: requires_grad = False\n",
            "distilbert.transformer.layer.2.ffn.lin1.bias: requires_grad = False\n",
            "distilbert.transformer.layer.2.ffn.lin2.weight: requires_grad = False\n",
            "distilbert.transformer.layer.2.ffn.lin2.bias: requires_grad = False\n",
            "distilbert.transformer.layer.2.output_layer_norm.weight: requires_grad = False\n",
            "distilbert.transformer.layer.2.output_layer_norm.bias: requires_grad = False\n",
            "distilbert.transformer.layer.3.attention.q_lin.weight: requires_grad = False\n",
            "distilbert.transformer.layer.3.attention.q_lin.bias: requires_grad = False\n",
            "distilbert.transformer.layer.3.attention.k_lin.weight: requires_grad = False\n",
            "distilbert.transformer.layer.3.attention.k_lin.bias: requires_grad = False\n",
            "distilbert.transformer.layer.3.attention.v_lin.weight: requires_grad = False\n",
            "distilbert.transformer.layer.3.attention.v_lin.bias: requires_grad = False\n",
            "distilbert.transformer.layer.3.attention.out_lin.weight: requires_grad = False\n",
            "distilbert.transformer.layer.3.attention.out_lin.bias: requires_grad = False\n",
            "distilbert.transformer.layer.3.sa_layer_norm.weight: requires_grad = False\n",
            "distilbert.transformer.layer.3.sa_layer_norm.bias: requires_grad = False\n",
            "distilbert.transformer.layer.3.ffn.lin1.weight: requires_grad = False\n",
            "distilbert.transformer.layer.3.ffn.lin1.bias: requires_grad = False\n",
            "distilbert.transformer.layer.3.ffn.lin2.weight: requires_grad = False\n",
            "distilbert.transformer.layer.3.ffn.lin2.bias: requires_grad = False\n",
            "distilbert.transformer.layer.3.output_layer_norm.weight: requires_grad = False\n",
            "distilbert.transformer.layer.3.output_layer_norm.bias: requires_grad = False\n",
            "distilbert.transformer.layer.4.attention.q_lin.weight: requires_grad = True\n",
            "distilbert.transformer.layer.4.attention.q_lin.bias: requires_grad = True\n",
            "distilbert.transformer.layer.4.attention.k_lin.weight: requires_grad = True\n",
            "distilbert.transformer.layer.4.attention.k_lin.bias: requires_grad = True\n",
            "distilbert.transformer.layer.4.attention.v_lin.weight: requires_grad = True\n",
            "distilbert.transformer.layer.4.attention.v_lin.bias: requires_grad = True\n",
            "distilbert.transformer.layer.4.attention.out_lin.weight: requires_grad = True\n",
            "distilbert.transformer.layer.4.attention.out_lin.bias: requires_grad = True\n",
            "distilbert.transformer.layer.4.sa_layer_norm.weight: requires_grad = True\n",
            "distilbert.transformer.layer.4.sa_layer_norm.bias: requires_grad = True\n",
            "distilbert.transformer.layer.4.ffn.lin1.weight: requires_grad = True\n",
            "distilbert.transformer.layer.4.ffn.lin1.bias: requires_grad = True\n",
            "distilbert.transformer.layer.4.ffn.lin2.weight: requires_grad = True\n",
            "distilbert.transformer.layer.4.ffn.lin2.bias: requires_grad = True\n",
            "distilbert.transformer.layer.4.output_layer_norm.weight: requires_grad = True\n",
            "distilbert.transformer.layer.4.output_layer_norm.bias: requires_grad = True\n",
            "distilbert.transformer.layer.5.attention.q_lin.weight: requires_grad = True\n",
            "distilbert.transformer.layer.5.attention.q_lin.bias: requires_grad = True\n",
            "distilbert.transformer.layer.5.attention.k_lin.weight: requires_grad = True\n",
            "distilbert.transformer.layer.5.attention.k_lin.bias: requires_grad = True\n",
            "distilbert.transformer.layer.5.attention.v_lin.weight: requires_grad = True\n",
            "distilbert.transformer.layer.5.attention.v_lin.bias: requires_grad = True\n",
            "distilbert.transformer.layer.5.attention.out_lin.weight: requires_grad = True\n",
            "distilbert.transformer.layer.5.attention.out_lin.bias: requires_grad = True\n",
            "distilbert.transformer.layer.5.sa_layer_norm.weight: requires_grad = True\n",
            "distilbert.transformer.layer.5.sa_layer_norm.bias: requires_grad = True\n",
            "distilbert.transformer.layer.5.ffn.lin1.weight: requires_grad = True\n",
            "distilbert.transformer.layer.5.ffn.lin1.bias: requires_grad = True\n",
            "distilbert.transformer.layer.5.ffn.lin2.weight: requires_grad = True\n",
            "distilbert.transformer.layer.5.ffn.lin2.bias: requires_grad = True\n",
            "distilbert.transformer.layer.5.output_layer_norm.weight: requires_grad = True\n",
            "distilbert.transformer.layer.5.output_layer_norm.bias: requires_grad = True\n",
            "pre_classifier.weight: requires_grad = True\n",
            "pre_classifier.bias: requires_grad = True\n",
            "classifier.weight: requires_grad = True\n",
            "classifier.bias: requires_grad = True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 11:13:38] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 11:13:38] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 11:13:38] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n",
            "[codecarbon WARNING @ 11:13:39] We saw that you have a Intel(R) Xeon(R) CPU @ 2.30GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 11:13:39] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
            "[codecarbon INFO @ 11:13:39] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 11:13:39] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 11:13:39] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 11:13:39]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 11:13:39]   Python version: 3.11.11\n",
            "[codecarbon INFO @ 11:13:39]   CodeCarbon version: 2.8.3\n",
            "[codecarbon INFO @ 11:13:39]   Available RAM : 12.675 GB\n",
            "[codecarbon INFO @ 11:13:39]   CPU count: 2\n",
            "[codecarbon INFO @ 11:13:39]   CPU model: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
            "[codecarbon INFO @ 11:13:39]   GPU count: 1\n",
            "[codecarbon INFO @ 11:13:39]   GPU model: 1 x Tesla T4\n",
            "[codecarbon INFO @ 11:13:39] Saving emissions data to file /content/emissions.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1560' max='1560' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1560/1560 12:12, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision Global</th>\n",
              "      <th>Recall Global</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.371100</td>\n",
              "      <td>0.278615</td>\n",
              "      <td>0.891200</td>\n",
              "      <td>0.892105</td>\n",
              "      <td>0.891492</td>\n",
              "      <td>0.891176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.246700</td>\n",
              "      <td>0.226337</td>\n",
              "      <td>0.911200</td>\n",
              "      <td>0.911554</td>\n",
              "      <td>0.911040</td>\n",
              "      <td>0.911147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.218300</td>\n",
              "      <td>0.224378</td>\n",
              "      <td>0.911200</td>\n",
              "      <td>0.913383</td>\n",
              "      <td>0.911638</td>\n",
              "      <td>0.911134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.177700</td>\n",
              "      <td>0.199595</td>\n",
              "      <td>0.923000</td>\n",
              "      <td>0.923029</td>\n",
              "      <td>0.922955</td>\n",
              "      <td>0.922984</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 11:13:54] Energy consumed for RAM : 0.000020 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:13:54] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:13:54] Energy consumed for all GPUs : 0.000272 kWh. Total GPU Power : 65.28084048730274 W\n",
            "[codecarbon INFO @ 11:13:54] 0.000469 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:14:09] Energy consumed for RAM : 0.000040 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:14:09] Energy consumed for all CPUs : 0.000354 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:14:09] Energy consumed for all GPUs : 0.000556 kWh. Total GPU Power : 67.99930012372101 W\n",
            "[codecarbon INFO @ 11:14:09] 0.000949 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:14:24] Energy consumed for RAM : 0.000059 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:14:24] Energy consumed for all CPUs : 0.000531 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:14:24] Energy consumed for all GPUs : 0.000841 kWh. Total GPU Power : 68.45995517695815 W\n",
            "[codecarbon INFO @ 11:14:24] 0.001431 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:14:39] Energy consumed for RAM : 0.000079 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:14:39] Energy consumed for all CPUs : 0.000708 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:14:39] Energy consumed for all GPUs : 0.001126 kWh. Total GPU Power : 68.47412210257171 W\n",
            "[codecarbon INFO @ 11:14:39] 0.001913 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:14:54] Energy consumed for RAM : 0.000099 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:14:54] Energy consumed for all CPUs : 0.000885 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:14:54] Energy consumed for all GPUs : 0.001410 kWh. Total GPU Power : 68.30415407539233 W\n",
            "[codecarbon INFO @ 11:14:54] 0.002395 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:15:09] Energy consumed for RAM : 0.000119 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:15:09] Energy consumed for all CPUs : 0.001062 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:15:09] Energy consumed for all GPUs : 0.001698 kWh. Total GPU Power : 68.86888610752737 W\n",
            "[codecarbon INFO @ 11:15:09] 0.002879 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:15:24] Energy consumed for RAM : 0.000139 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:15:24] Energy consumed for all CPUs : 0.001239 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:15:24] Energy consumed for all GPUs : 0.001984 kWh. Total GPU Power : 68.75297965588626 W\n",
            "[codecarbon INFO @ 11:15:24] 0.003361 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:15:39] Energy consumed for RAM : 0.000158 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:15:39] Energy consumed for all CPUs : 0.001416 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:15:39] Energy consumed for all GPUs : 0.002269 kWh. Total GPU Power : 68.43912874356452 W\n",
            "[codecarbon INFO @ 11:15:39] 0.003844 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:15:39] 0.009140 g.CO2eq/s mean an estimation of 288.2415989436546 kg.CO2eq/year\n",
            "[codecarbon INFO @ 11:15:54] Energy consumed for RAM : 0.000178 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:15:54] Energy consumed for all CPUs : 0.001593 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:15:54] Energy consumed for all GPUs : 0.002556 kWh. Total GPU Power : 68.84458787226292 W\n",
            "[codecarbon INFO @ 11:15:54] 0.004327 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:16:09] Energy consumed for RAM : 0.000198 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:16:09] Energy consumed for all CPUs : 0.001770 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:16:09] Energy consumed for all GPUs : 0.002843 kWh. Total GPU Power : 69.03389074166975 W\n",
            "[codecarbon INFO @ 11:16:09] 0.004812 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:16:24] Energy consumed for RAM : 0.000218 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:16:24] Energy consumed for all CPUs : 0.001947 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:16:24] Energy consumed for all GPUs : 0.003130 kWh. Total GPU Power : 68.68811818355191 W\n",
            "[codecarbon INFO @ 11:16:24] 0.005295 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:16:39] Energy consumed for RAM : 0.000238 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:16:39] Energy consumed for all CPUs : 0.002124 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:16:39] Energy consumed for all GPUs : 0.003415 kWh. Total GPU Power : 68.50071062594027 W\n",
            "[codecarbon INFO @ 11:16:39] 0.005777 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:16:54] Energy consumed for RAM : 0.000257 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:16:54] Energy consumed for all CPUs : 0.002301 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:16:54] Energy consumed for all GPUs : 0.003702 kWh. Total GPU Power : 69.19314742429465 W\n",
            "[codecarbon INFO @ 11:16:54] 0.006261 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:17:09] Energy consumed for RAM : 0.000277 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:17:09] Energy consumed for all CPUs : 0.002478 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:17:09] Energy consumed for all GPUs : 0.003989 kWh. Total GPU Power : 68.671268860173 W\n",
            "[codecarbon INFO @ 11:17:09] 0.006744 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:17:24] Energy consumed for RAM : 0.000297 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:17:24] Energy consumed for all CPUs : 0.002655 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:17:24] Energy consumed for all GPUs : 0.004272 kWh. Total GPU Power : 68.01656032352722 W\n",
            "[codecarbon INFO @ 11:17:24] 0.007224 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:17:39] Energy consumed for RAM : 0.000317 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:17:39] Energy consumed for all CPUs : 0.002832 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:17:39] Energy consumed for all GPUs : 0.004559 kWh. Total GPU Power : 68.84036209396173 W\n",
            "[codecarbon INFO @ 11:17:39] 0.007708 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:17:39] 0.009189 g.CO2eq/s mean an estimation of 289.77866171165306 kg.CO2eq/year\n",
            "[codecarbon INFO @ 11:17:54] Energy consumed for RAM : 0.000336 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:17:54] Energy consumed for all CPUs : 0.003009 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:17:54] Energy consumed for all GPUs : 0.004845 kWh. Total GPU Power : 68.5617198437469 W\n",
            "[codecarbon INFO @ 11:17:54] 0.008190 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:18:09] Energy consumed for RAM : 0.000356 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:18:09] Energy consumed for all CPUs : 0.003186 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:18:09] Energy consumed for all GPUs : 0.005131 kWh. Total GPU Power : 68.67315574893895 W\n",
            "[codecarbon INFO @ 11:18:09] 0.008674 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:18:24] Energy consumed for RAM : 0.000376 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:18:24] Energy consumed for all CPUs : 0.003363 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:18:24] Energy consumed for all GPUs : 0.005417 kWh. Total GPU Power : 68.69862620979896 W\n",
            "[codecarbon INFO @ 11:18:24] 0.009156 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:18:39] Energy consumed for RAM : 0.000396 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:18:39] Energy consumed for all CPUs : 0.003540 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:18:39] Energy consumed for all GPUs : 0.005703 kWh. Total GPU Power : 68.71551061471905 W\n",
            "[codecarbon INFO @ 11:18:39] 0.009640 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:18:54] Energy consumed for RAM : 0.000416 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:18:54] Energy consumed for all CPUs : 0.003718 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:18:54] Energy consumed for all GPUs : 0.005988 kWh. Total GPU Power : 68.3782673683803 W\n",
            "[codecarbon INFO @ 11:18:54] 0.010122 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:19:09] Energy consumed for RAM : 0.000435 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:19:09] Energy consumed for all CPUs : 0.003895 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:19:09] Energy consumed for all GPUs : 0.006276 kWh. Total GPU Power : 69.04354987215673 W\n",
            "[codecarbon INFO @ 11:19:09] 0.010606 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:19:24] Energy consumed for RAM : 0.000455 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:19:24] Energy consumed for all CPUs : 0.004072 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:19:24] Energy consumed for all GPUs : 0.006561 kWh. Total GPU Power : 68.44409503812453 W\n",
            "[codecarbon INFO @ 11:19:24] 0.011089 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:19:39] Energy consumed for RAM : 0.000475 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:19:39] Energy consumed for all CPUs : 0.004249 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:19:39] Energy consumed for all GPUs : 0.006848 kWh. Total GPU Power : 68.70046613817827 W\n",
            "[codecarbon INFO @ 11:19:39] 0.011572 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:19:39] 0.009188 g.CO2eq/s mean an estimation of 289.7666297949634 kg.CO2eq/year\n",
            "[codecarbon INFO @ 11:19:54] Energy consumed for RAM : 0.000495 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:19:54] Energy consumed for all CPUs : 0.004426 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:19:54] Energy consumed for all GPUs : 0.007134 kWh. Total GPU Power : 68.61057680296223 W\n",
            "[codecarbon INFO @ 11:19:54] 0.012054 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:20:09] Energy consumed for RAM : 0.000515 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:20:09] Energy consumed for all CPUs : 0.004603 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:20:09] Energy consumed for all GPUs : 0.007420 kWh. Total GPU Power : 68.68321797948964 W\n",
            "[codecarbon INFO @ 11:20:09] 0.012538 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:20:24] Energy consumed for RAM : 0.000534 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:20:24] Energy consumed for all CPUs : 0.004780 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:20:24] Energy consumed for all GPUs : 0.007705 kWh. Total GPU Power : 68.54245709987921 W\n",
            "[codecarbon INFO @ 11:20:24] 0.013020 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:20:39] Energy consumed for RAM : 0.000554 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:20:39] Energy consumed for all CPUs : 0.004957 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:20:39] Energy consumed for all GPUs : 0.007992 kWh. Total GPU Power : 68.71842935284981 W\n",
            "[codecarbon INFO @ 11:20:39] 0.013503 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:20:54] Energy consumed for RAM : 0.000574 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:20:54] Energy consumed for all CPUs : 0.005134 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:20:54] Energy consumed for all GPUs : 0.008279 kWh. Total GPU Power : 68.97514891378621 W\n",
            "[codecarbon INFO @ 11:20:54] 0.013988 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:21:09] Energy consumed for RAM : 0.000594 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:21:09] Energy consumed for all CPUs : 0.005311 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:21:09] Energy consumed for all GPUs : 0.008565 kWh. Total GPU Power : 68.48675973731505 W\n",
            "[codecarbon INFO @ 11:21:09] 0.014470 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:21:24] Energy consumed for RAM : 0.000614 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:21:24] Energy consumed for all CPUs : 0.005488 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:21:24] Energy consumed for all GPUs : 0.008852 kWh. Total GPU Power : 68.8856245614451 W\n",
            "[codecarbon INFO @ 11:21:24] 0.014954 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:21:39] Energy consumed for RAM : 0.000634 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:21:39] Energy consumed for all CPUs : 0.005666 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:21:39] Energy consumed for all GPUs : 0.009138 kWh. Total GPU Power : 68.55086089486024 W\n",
            "[codecarbon INFO @ 11:21:39] 0.015437 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:21:39] 0.009190 g.CO2eq/s mean an estimation of 289.8208815252934 kg.CO2eq/year\n",
            "[codecarbon INFO @ 11:21:54] Energy consumed for RAM : 0.000653 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:21:54] Energy consumed for all CPUs : 0.005843 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:21:54] Energy consumed for all GPUs : 0.009423 kWh. Total GPU Power : 68.52882686666693 W\n",
            "[codecarbon INFO @ 11:21:54] 0.015919 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:22:09] Energy consumed for RAM : 0.000673 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:22:09] Energy consumed for all CPUs : 0.006020 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:22:09] Energy consumed for all GPUs : 0.009708 kWh. Total GPU Power : 68.47865926006051 W\n",
            "[codecarbon INFO @ 11:22:09] 0.016401 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:22:24] Energy consumed for RAM : 0.000693 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:22:24] Energy consumed for all CPUs : 0.006197 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:22:24] Energy consumed for all GPUs : 0.009995 kWh. Total GPU Power : 68.89521105335551 W\n",
            "[codecarbon INFO @ 11:22:24] 0.016885 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:22:39] Energy consumed for RAM : 0.000713 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:22:39] Energy consumed for all CPUs : 0.006374 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:22:39] Energy consumed for all GPUs : 0.010282 kWh. Total GPU Power : 68.69111473905117 W\n",
            "[codecarbon INFO @ 11:22:39] 0.017368 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:22:54] Energy consumed for RAM : 0.000733 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:22:54] Energy consumed for all CPUs : 0.006551 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:22:54] Energy consumed for all GPUs : 0.010570 kWh. Total GPU Power : 69.17864323586676 W\n",
            "[codecarbon INFO @ 11:22:54] 0.017854 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:23:09] Energy consumed for RAM : 0.000752 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:23:09] Energy consumed for all CPUs : 0.006728 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:23:09] Energy consumed for all GPUs : 0.010857 kWh. Total GPU Power : 68.80255556289161 W\n",
            "[codecarbon INFO @ 11:23:09] 0.018337 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:23:24] Energy consumed for RAM : 0.000772 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:23:24] Energy consumed for all CPUs : 0.006905 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:23:24] Energy consumed for all GPUs : 0.011144 kWh. Total GPU Power : 68.79057177635895 W\n",
            "[codecarbon INFO @ 11:23:24] 0.018821 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:23:39] Energy consumed for RAM : 0.000792 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:23:39] Energy consumed for all CPUs : 0.007082 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:23:39] Energy consumed for all GPUs : 0.011430 kWh. Total GPU Power : 68.82386100247979 W\n",
            "[codecarbon INFO @ 11:23:39] 0.019304 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:23:39] 0.009197 g.CO2eq/s mean an estimation of 290.02489297093473 kg.CO2eq/year\n",
            "[codecarbon INFO @ 11:23:54] Energy consumed for RAM : 0.000812 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:23:54] Energy consumed for all CPUs : 0.007259 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:23:54] Energy consumed for all GPUs : 0.011718 kWh. Total GPU Power : 69.04816253051578 W\n",
            "[codecarbon INFO @ 11:23:54] 0.019789 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:24:09] Energy consumed for RAM : 0.000832 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:24:09] Energy consumed for all CPUs : 0.007436 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:24:09] Energy consumed for all GPUs : 0.012002 kWh. Total GPU Power : 68.1137386868307 W\n",
            "[codecarbon INFO @ 11:24:09] 0.020270 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:24:24] Energy consumed for RAM : 0.000851 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:24:24] Energy consumed for all CPUs : 0.007613 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:24:24] Energy consumed for all GPUs : 0.012286 kWh. Total GPU Power : 68.33905519408725 W\n",
            "[codecarbon INFO @ 11:24:24] 0.020751 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:24:39] Energy consumed for RAM : 0.000871 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:24:39] Energy consumed for all CPUs : 0.007790 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:24:39] Energy consumed for all GPUs : 0.012574 kWh. Total GPU Power : 69.08430398570374 W\n",
            "[codecarbon INFO @ 11:24:39] 0.021235 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:24:54] Energy consumed for RAM : 0.000891 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:24:54] Energy consumed for all CPUs : 0.007967 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:24:54] Energy consumed for all GPUs : 0.012860 kWh. Total GPU Power : 68.60825685511053 W\n",
            "[codecarbon INFO @ 11:24:54] 0.021718 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:25:09] Energy consumed for RAM : 0.000911 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:25:09] Energy consumed for all CPUs : 0.008145 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:25:09] Energy consumed for all GPUs : 0.013144 kWh. Total GPU Power : 68.0999277770629 W\n",
            "[codecarbon INFO @ 11:25:09] 0.022199 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:25:24] Energy consumed for RAM : 0.000931 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:25:24] Energy consumed for all CPUs : 0.008322 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:25:24] Energy consumed for all GPUs : 0.013431 kWh. Total GPU Power : 68.96667885435839 W\n",
            "[codecarbon INFO @ 11:25:24] 0.022684 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:25:39] Energy consumed for RAM : 0.000950 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:25:40] Energy consumed for all CPUs : 0.008499 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:25:40] Energy consumed for all GPUs : 0.013714 kWh. Total GPU Power : 67.83550721980444 W\n",
            "[codecarbon INFO @ 11:25:40] 0.023163 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 11:25:40] 0.009176 g.CO2eq/s mean an estimation of 289.3827412421082 kg.CO2eq/year\n",
            "[codecarbon INFO @ 11:25:52] Energy consumed for RAM : 0.000967 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 11:25:52] Energy consumed for all CPUs : 0.008652 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 11:25:52] Energy consumed for all GPUs : 0.013962 kWh. Total GPU Power : 68.90898207400926 W\n",
            "[codecarbon INFO @ 11:25:52] 0.023582 kWh of electricity used since the beginning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def generate_metrics_report(trainer, final_metrics, training_args, emissions, tokenizer=None, lora_config=None):\n",
        "    \"\"\"\n",
        "    Génère un rapport compact avec les métriques clés.\n",
        "    Affiche automatiquement les infos liées à LoRA si `lora_config` est fourni.\n",
        "    \"\"\"\n",
        "    def safe_format(value):\n",
        "        return f\"{value:.4f}\" if isinstance(value, (int, float)) else str(value)\n",
        "\n",
        "    history = pd.DataFrame(trainer.state.log_history)\n",
        "\n",
        "    # Calcul du temps moyen par époque\n",
        "    if 'epoch' in history.columns and 'train_runtime' in history.columns:\n",
        "        epoch_times = history[history['epoch'].notna()].groupby('epoch')['train_runtime'].mean()\n",
        "        mean_epoch_time = epoch_times.mean() if not epoch_times.empty else \"N/A\"\n",
        "    else:\n",
        "        mean_epoch_time = \"N/A\"\n",
        "\n",
        "    # Section LoRA (optionnelle)\n",
        "    lora_section = (\n",
        "        f\"- **LoRA Config** : r={lora_config.r}, alpha={lora_config.lora_alpha}, dropout={lora_config.lora_dropout}\"\n",
        "        if lora_config else \"- **LoRA** : non utilisé\"\n",
        "    )\n",
        "\n",
        "    # Choix du nom de fichier / courbe\n",
        "    suffix = \"_lora\" if lora_config else \"_sans_lora\"\n",
        "    report_path = f\"./results{suffix}/training_report{suffix}.txt\"\n",
        "    learning_curve_path = f\"./results{suffix}/learning_curves{suffix}.png\"\n",
        "\n",
        "    report = f\"\"\"\n",
        "# 📊 Rapport d'entraînement et d'évaluation\n",
        "\n",
        "## 🔍 **Résultats**\n",
        "- **Accuracy** : {safe_format(final_metrics.get('eval_accuracy', 'N/A'))}\n",
        "- **F1-score (macro)** : {safe_format(final_metrics.get('eval_f1_macro', 'N/A'))}\n",
        "- **Precision globale** : {safe_format(final_metrics.get('eval_precision_global', 'N/A'))}\n",
        "- **Recall global** : {safe_format(final_metrics.get('eval_recall_global', 'N/A'))}\n",
        "- **Loss finale** : {safe_format(final_metrics.get('eval_loss', 'N/A'))}\n",
        "\n",
        "## ⚙️ **Hyperparamètres**\n",
        "- **Epochs** : {training_args.num_train_epochs}\n",
        "- **Batch Size (train / eval)** : {training_args.per_device_train_batch_size} / {training_args.per_device_eval_batch_size}\n",
        "- **Gradient Accumulation Steps** : {training_args.gradient_accumulation_steps}\n",
        "- **Learning Rate** : {training_args.learning_rate}\n",
        "- **Weight Decay** : {training_args.weight_decay}\n",
        "- **Warmup Steps** : {training_args.warmup_steps}\n",
        "- **Scheduler** : {training_args.lr_scheduler_type}\n",
        "- **Max Grad Norm** : {training_args.max_grad_norm}\n",
        "- **Seed** : {training_args.seed}\n",
        "{lora_section}\n",
        "\n",
        "## 🧠 **Tokenizer**\n",
        "- **Tokenizer utilisé** : {getattr(tokenizer, 'name_or_path', 'Non spécifié') if tokenizer else 'Non fourni'}\n",
        "\n",
        "## ⏱ **Temps d'entraînement**\n",
        "- **Temps moyen par époque** : {safe_format(mean_epoch_time)} sec\n",
        "\n",
        "## 🌱 **Empreinte carbone**\n",
        "- **CO₂ estimé** : {safe_format(emissions)} kg\n",
        "\n",
        "\"\"\"\n",
        "    with open(report_path, \"w\") as f:\n",
        "        f.write(report)\n",
        "    print(report)\n"
      ],
      "metadata": {
        "id": "GIo8GEUglqyA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_metrics = trainer.evaluate()\n",
        "# generate_metrics_report(trainer, final_metrics, training_args, emissions, tokenizer, lora_config)\n",
        "generate_metrics_report(trainer, final_metrics, training_args, emissions, tokenizer)\n",
        "print(final_metrics)"
      ],
      "metadata": {
        "id": "dkE4b4UPuBhm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630
        },
        "outputId": "20ce3393-dc4e-420e-ada4-538ec4aed332"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='157' max='157' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [157/157 00:23]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "# 📊 Rapport d'entraînement et d'évaluation\n",
            "\n",
            "## 🔍 **Résultats**\n",
            "- **Accuracy** : 0.9230\n",
            "- **F1-score (macro)** : 0.9230\n",
            "- **Precision globale** : 0.9230\n",
            "- **Recall global** : 0.9230\n",
            "- **Loss finale** : 0.1996\n",
            "\n",
            "## ⚙️ **Hyperparamètres**\n",
            "- **Epochs** : 5\n",
            "- **Batch Size (train / eval)** : 32 / 32\n",
            "- **Gradient Accumulation Steps** : 2\n",
            "- **Learning Rate** : 3e-05\n",
            "- **Weight Decay** : 0.05\n",
            "- **Warmup Steps** : 1000\n",
            "- **Scheduler** : SchedulerType.COSINE\n",
            "- **Max Grad Norm** : 0.8\n",
            "- **Seed** : 123\n",
            "- **LoRA** : non utilisé\n",
            "\n",
            "## 🧠 **Tokenizer**\n",
            "- **Tokenizer utilisé** : distilbert-base-uncased\n",
            "\n",
            "## ⏱ **Temps d'entraînement**\n",
            "- **Temps moyen par époque** : 733.0113 sec\n",
            "\n",
            "## 🌱 **Empreinte carbone**\n",
            "- **CO₂ estimé** : 0.0067 kg\n",
            "\n",
            "\n",
            "{'eval_loss': 0.19959479570388794, 'eval_accuracy': 0.923, 'eval_precision_global': 0.9230289574498597, 'eval_recall_global': 0.9229548328023018, 'eval_f1_macro': 0.9229835831805908, 'eval_runtime': 24.1738, 'eval_samples_per_second': 206.835, 'eval_steps_per_second': 6.495, 'epoch': 4.9856}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r mon_dossier2.zip ./"
      ],
      "metadata": {
        "id": "tD9h6vAF_FPj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6ae4c7f-25fe-4cf2-8e68-66b5b5654202"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: .config/ (stored 0%)\n",
            "  adding: .config/config_sentinel (stored 0%)\n",
            "  adding: .config/hidden_gcloud_config_universe_descriptor_data_cache_configs.db (deflated 97%)\n",
            "  adding: .config/configurations/ (stored 0%)\n",
            "  adding: .config/configurations/config_default (deflated 15%)\n",
            "  adding: .config/gce (stored 0%)\n",
            "  adding: .config/.last_survey_prompt.yaml (stored 0%)\n",
            "  adding: .config/active_config (stored 0%)\n",
            "  adding: .config/default_configs.db (deflated 98%)\n",
            "  adding: .config/.last_update_check.json (deflated 23%)\n",
            "  adding: .config/logs/ (stored 0%)\n",
            "  adding: .config/logs/2025.04.07/ (stored 0%)\n",
            "  adding: .config/logs/2025.04.07/13.42.43.503346.log (deflated 57%)\n",
            "  adding: .config/logs/2025.04.07/13.42.02.070730.log (deflated 92%)\n",
            "  adding: .config/logs/2025.04.07/13.42.32.824024.log (deflated 86%)\n",
            "  adding: .config/logs/2025.04.07/13.42.24.146310.log (deflated 58%)\n",
            "  adding: .config/logs/2025.04.07/13.42.34.302585.log (deflated 58%)\n",
            "  adding: .config/logs/2025.04.07/13.42.44.251076.log (deflated 56%)\n",
            "  adding: .config/.last_opt_in_prompt.yaml (stored 0%)\n",
            "  adding: results/ (stored 0%)\n",
            "  adding: mon_dossier.zip (stored 0%)\n",
            "  adding: results_lora/ (stored 0%)\n",
            "  adding: results_lora/checkpoint-939/ (stored 0%)\n",
            "  adding: results_lora/checkpoint-939/special_tokens_map.json (deflated 42%)\n",
            "  adding: results_lora/checkpoint-939/training_args.bin (deflated 51%)\n",
            "  adding: results_lora/checkpoint-939/trainer_state.json (deflated 72%)\n",
            "  adding: results_lora/checkpoint-939/rng_state.pth (deflated 25%)\n",
            "  adding: results_lora/checkpoint-939/adapter_model.safetensors (deflated 7%)\n",
            "  adding: results_lora/checkpoint-939/README.md (deflated 66%)\n",
            "  adding: results_lora/checkpoint-939/scaler.pt (deflated 60%)\n",
            "  adding: results_lora/checkpoint-939/scheduler.pt (deflated 56%)\n",
            "  adding: results_lora/checkpoint-939/tokenizer_config.json (deflated 75%)\n",
            "  adding: results_lora/checkpoint-939/optimizer.pt (deflated 8%)\n",
            "  adding: results_lora/checkpoint-939/adapter_config.json (deflated 54%)\n",
            "  adding: results_lora/checkpoint-939/vocab.txt (deflated 53%)\n",
            "  adding: results_lora/checkpoint-1560/ (stored 0%)\n",
            "  adding: results_lora/checkpoint-1560/special_tokens_map.json (deflated 42%)\n",
            "  adding: results_lora/checkpoint-1560/training_args.bin (deflated 51%)\n",
            "  adding: results_lora/checkpoint-1560/trainer_state.json (deflated 74%)\n",
            "  adding: results_lora/checkpoint-1560/rng_state.pth (deflated 25%)\n",
            "  adding: results_lora/checkpoint-1560/adapter_model.safetensors (deflated 7%)\n",
            "  adding: results_lora/checkpoint-1560/README.md (deflated 66%)\n",
            "  adding: results_lora/checkpoint-1560/scaler.pt (deflated 60%)\n",
            "  adding: results_lora/checkpoint-1560/scheduler.pt (deflated 57%)\n",
            "  adding: results_lora/checkpoint-1560/tokenizer_config.json (deflated 75%)\n",
            "  adding: results_lora/checkpoint-1560/optimizer.pt (deflated 7%)\n",
            "  adding: results_lora/checkpoint-1560/adapter_config.json (deflated 54%)\n",
            "  adding: results_lora/checkpoint-1560/vocab.txt (deflated 53%)\n",
            "  adding: results_lora/checkpoint-313/ (stored 0%)\n",
            "  adding: results_lora/checkpoint-313/special_tokens_map.json (deflated 42%)\n",
            "  adding: results_lora/checkpoint-313/training_args.bin (deflated 51%)\n",
            "  adding: results_lora/checkpoint-313/trainer_state.json (deflated 64%)\n",
            "  adding: results_lora/checkpoint-313/rng_state.pth (deflated 25%)\n",
            "  adding: results_lora/checkpoint-313/adapter_model.safetensors (deflated 7%)\n",
            "  adding: results_lora/checkpoint-313/README.md (deflated 66%)\n",
            "  adding: results_lora/checkpoint-313/scaler.pt (deflated 60%)\n",
            "  adding: results_lora/checkpoint-313/scheduler.pt (deflated 56%)\n",
            "  adding: results_lora/checkpoint-313/tokenizer_config.json (deflated 75%)\n",
            "  adding: results_lora/checkpoint-313/optimizer.pt (deflated 9%)\n",
            "  adding: results_lora/checkpoint-313/adapter_config.json (deflated 54%)\n",
            "  adding: results_lora/checkpoint-313/vocab.txt (deflated 53%)\n",
            "  adding: results_lora/checkpoint-1252/ (stored 0%)\n",
            "  adding: results_lora/checkpoint-1252/special_tokens_map.json (deflated 42%)\n",
            "  adding: results_lora/checkpoint-1252/training_args.bin (deflated 51%)\n",
            "  adding: results_lora/checkpoint-1252/trainer_state.json (deflated 73%)\n",
            "  adding: results_lora/checkpoint-1252/rng_state.pth (deflated 25%)\n",
            "  adding: results_lora/checkpoint-1252/adapter_model.safetensors (deflated 7%)\n",
            "  adding: results_lora/checkpoint-1252/README.md (deflated 66%)\n",
            "  adding: results_lora/checkpoint-1252/scaler.pt (deflated 60%)\n",
            "  adding: results_lora/checkpoint-1252/scheduler.pt (deflated 56%)\n",
            "  adding: results_lora/checkpoint-1252/tokenizer_config.json (deflated 75%)\n",
            "  adding: results_lora/checkpoint-1252/optimizer.pt (deflated 8%)\n",
            "  adding: results_lora/checkpoint-1252/adapter_config.json (deflated 54%)\n",
            "  adding: results_lora/checkpoint-1252/vocab.txt (deflated 53%)\n",
            "  adding: results_lora/checkpoint-626/ (stored 0%)\n",
            "  adding: results_lora/checkpoint-626/special_tokens_map.json (deflated 42%)\n",
            "  adding: results_lora/checkpoint-626/training_args.bin (deflated 51%)\n",
            "  adding: results_lora/checkpoint-626/trainer_state.json (deflated 70%)\n",
            "  adding: results_lora/checkpoint-626/rng_state.pth (deflated 25%)\n",
            "  adding: results_lora/checkpoint-626/adapter_model.safetensors (deflated 7%)\n",
            "  adding: results_lora/checkpoint-626/README.md (deflated 66%)\n",
            "  adding: results_lora/checkpoint-626/scaler.pt (deflated 60%)\n",
            "  adding: results_lora/checkpoint-626/scheduler.pt (deflated 55%)\n",
            "  adding: results_lora/checkpoint-626/tokenizer_config.json (deflated 75%)\n",
            "  adding: results_lora/checkpoint-626/optimizer.pt (deflated 8%)\n",
            "  adding: results_lora/checkpoint-626/adapter_config.json (deflated 54%)\n",
            "  adding: results_lora/checkpoint-626/vocab.txt (deflated 53%)\n",
            "  adding: results_lora/training_report_lora.txt (deflated 38%)\n",
            "  adding: emissions.csv (deflated 49%)\n",
            "  adding: results_sans_lora/ (stored 0%)\n",
            "  adding: results_sans_lora/training_report_sans_lora.txt (deflated 40%)\n",
            "  adding: sample_data/ (stored 0%)\n",
            "  adding: sample_data/anscombe.json (deflated 83%)\n",
            "  adding: sample_data/README.md (deflated 39%)\n",
            "  adding: sample_data/mnist_test.csv (deflated 88%)\n",
            "  adding: sample_data/california_housing_test.csv (deflated 76%)\n",
            "  adding: sample_data/mnist_train_small.csv (deflated 88%)\n",
            "  adding: sample_data/california_housing_train.csv (deflated 79%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"mon_dossier2.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "IXwCX0NeLqs6",
        "outputId": "4ef2715f-c6b7-47ea-bd9d-657bd8cdf30b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_36e1e25d-bfe7-4e94-858b-9c122ddbd59b\", \"mon_dossier2.zip\", 97640304)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zazeoNYD7xGl"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4249c519dd9246c894c68e668b61391a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d593b89e891447f9b939598b50287438",
              "IPY_MODEL_6cdd845d70ee4b5790e66de5f9f74a9d",
              "IPY_MODEL_00e9e5a21c6c4fb7a3101246a57b93b7"
            ],
            "layout": "IPY_MODEL_a1d4fab129ff4d72aa04828f954e2910"
          }
        },
        "d593b89e891447f9b939598b50287438": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ddb61e2427c4a3080505295668cbb10",
            "placeholder": "​",
            "style": "IPY_MODEL_3a6f4bbb40fb41cc8e69d8db515b994b",
            "value": "Map: 100%"
          }
        },
        "6cdd845d70ee4b5790e66de5f9f74a9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22ac7d72c47c49e98566239a0b14986a",
            "max": 20000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_066e0ac96cd046c0b21fcef71cde1b1d",
            "value": 20000
          }
        },
        "00e9e5a21c6c4fb7a3101246a57b93b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4b0318d418e4b189fd891a47ad4bae7",
            "placeholder": "​",
            "style": "IPY_MODEL_5b8307a0df6645c2bfb2ccc89f3afc40",
            "value": " 20000/20000 [01:32&lt;00:00, 183.17 examples/s]"
          }
        },
        "a1d4fab129ff4d72aa04828f954e2910": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ddb61e2427c4a3080505295668cbb10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a6f4bbb40fb41cc8e69d8db515b994b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22ac7d72c47c49e98566239a0b14986a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "066e0ac96cd046c0b21fcef71cde1b1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a4b0318d418e4b189fd891a47ad4bae7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b8307a0df6645c2bfb2ccc89f3afc40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e233da595f9949658d51c115a6e25365": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f9c56158a7264da5aa6af4d7b908089e",
              "IPY_MODEL_b92b9daddf704c2d81c1147b08d644e7",
              "IPY_MODEL_495fe494e10d49e5bb6752706531d578"
            ],
            "layout": "IPY_MODEL_04742e46ed8644d4a90c8173a9eabf58"
          }
        },
        "f9c56158a7264da5aa6af4d7b908089e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a505ca059bec4c5ba1d2056d5235f4cd",
            "placeholder": "​",
            "style": "IPY_MODEL_bb4cc9990194460e9856549974d27b43",
            "value": "Map: 100%"
          }
        },
        "b92b9daddf704c2d81c1147b08d644e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e05b7cd331d43e385f293e1ab8d6162",
            "max": 5000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2f3ab07766544850a6fde2d61792aafd",
            "value": 5000
          }
        },
        "495fe494e10d49e5bb6752706531d578": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b473eaf60b5849bfb76b25796f6e08dc",
            "placeholder": "​",
            "style": "IPY_MODEL_4da492780c5348cf868266154a09c44f",
            "value": " 5000/5000 [00:21&lt;00:00, 242.11 examples/s]"
          }
        },
        "04742e46ed8644d4a90c8173a9eabf58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a505ca059bec4c5ba1d2056d5235f4cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb4cc9990194460e9856549974d27b43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e05b7cd331d43e385f293e1ab8d6162": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f3ab07766544850a6fde2d61792aafd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b473eaf60b5849bfb76b25796f6e08dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4da492780c5348cf868266154a09c44f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}