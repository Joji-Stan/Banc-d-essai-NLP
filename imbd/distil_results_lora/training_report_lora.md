
# ğŸ“Š Rapport d'entraÃ®nement et d'Ã©valuation

## ğŸ” **RÃ©sultats**
- **Accuracy** : 0.9026
- **F1-score (macro)** : 0.9026
- **Precision globale** : 0.9026
- **Recall global** : 0.9027
- **Loss finale** : 0.2434

## âš™ï¸ **HyperparamÃ¨tres**
- **Epochs** : 5
- **Batch Size (train / eval)** : 32 / 32
- **Gradient Accumulation Steps** : 2
- **Learning Rate** : 3e-05
- **Weight Decay** : 0.05
- **Warmup Steps** : 1000
- **Scheduler** : SchedulerType.COSINE
- **Max Grad Norm** : 0.8
- **Seed** : 123
- **LoRA Config** : r=8, alpha=16, dropout=0.1

## ğŸ§  **Tokenizer**
- **Tokenizer utilisÃ©** : distilbert-base-uncased

## â± **Temps d'entraÃ®nement**
- **Temps moyen par Ã©poque** : 1136.7510 sec

## ğŸŒ± **Empreinte carbone**
- **COâ‚‚ estimÃ©** : 0.0104 kg

