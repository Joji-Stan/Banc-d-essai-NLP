{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 1425,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.007017543859649123,
      "grad_norm": 1.2604175806045532,
      "learning_rate": 3.994385964912281e-05,
      "loss": 3.1428,
      "step": 10
    },
    {
      "epoch": 0.014035087719298246,
      "grad_norm": 1.3774422407150269,
      "learning_rate": 3.988771929824561e-05,
      "loss": 3.1305,
      "step": 20
    },
    {
      "epoch": 0.021052631578947368,
      "grad_norm": 1.4562627077102661,
      "learning_rate": 3.9831578947368425e-05,
      "loss": 3.1109,
      "step": 30
    },
    {
      "epoch": 0.028070175438596492,
      "grad_norm": 1.4487625360488892,
      "learning_rate": 3.977543859649123e-05,
      "loss": 3.0808,
      "step": 40
    },
    {
      "epoch": 0.03508771929824561,
      "grad_norm": 1.5011128187179565,
      "learning_rate": 3.9719298245614034e-05,
      "loss": 3.0743,
      "step": 50
    },
    {
      "epoch": 0.042105263157894736,
      "grad_norm": 1.277342438697815,
      "learning_rate": 3.9663157894736846e-05,
      "loss": 3.0305,
      "step": 60
    },
    {
      "epoch": 0.04912280701754386,
      "grad_norm": 1.5399539470672607,
      "learning_rate": 3.960701754385965e-05,
      "loss": 2.9921,
      "step": 70
    },
    {
      "epoch": 0.056140350877192984,
      "grad_norm": 1.383981466293335,
      "learning_rate": 3.955087719298246e-05,
      "loss": 2.9621,
      "step": 80
    },
    {
      "epoch": 0.06315789473684211,
      "grad_norm": 1.611066460609436,
      "learning_rate": 3.949473684210527e-05,
      "loss": 2.913,
      "step": 90
    },
    {
      "epoch": 0.07017543859649122,
      "grad_norm": 1.7793769836425781,
      "learning_rate": 3.943859649122807e-05,
      "loss": 2.8376,
      "step": 100
    },
    {
      "epoch": 0.07719298245614035,
      "grad_norm": 1.577679991722107,
      "learning_rate": 3.9382456140350883e-05,
      "loss": 2.8608,
      "step": 110
    },
    {
      "epoch": 0.08421052631578947,
      "grad_norm": 2.0095579624176025,
      "learning_rate": 3.932631578947369e-05,
      "loss": 2.8454,
      "step": 120
    },
    {
      "epoch": 0.0912280701754386,
      "grad_norm": 1.786095142364502,
      "learning_rate": 3.927017543859649e-05,
      "loss": 2.8373,
      "step": 130
    },
    {
      "epoch": 0.09824561403508772,
      "grad_norm": 1.9585458040237427,
      "learning_rate": 3.92140350877193e-05,
      "loss": 2.8047,
      "step": 140
    },
    {
      "epoch": 0.10526315789473684,
      "grad_norm": 1.7891299724578857,
      "learning_rate": 3.915789473684211e-05,
      "loss": 2.8204,
      "step": 150
    },
    {
      "epoch": 0.11228070175438597,
      "grad_norm": 2.3338568210601807,
      "learning_rate": 3.9101754385964914e-05,
      "loss": 2.7982,
      "step": 160
    },
    {
      "epoch": 0.11929824561403508,
      "grad_norm": 1.973358392715454,
      "learning_rate": 3.904561403508772e-05,
      "loss": 2.8458,
      "step": 170
    },
    {
      "epoch": 0.12631578947368421,
      "grad_norm": 2.152691125869751,
      "learning_rate": 3.898947368421053e-05,
      "loss": 2.8232,
      "step": 180
    },
    {
      "epoch": 0.13333333333333333,
      "grad_norm": 2.107297658920288,
      "learning_rate": 3.8933333333333336e-05,
      "loss": 2.7975,
      "step": 190
    },
    {
      "epoch": 0.14035087719298245,
      "grad_norm": 2.069648265838623,
      "learning_rate": 3.887719298245615e-05,
      "loss": 2.8476,
      "step": 200
    },
    {
      "epoch": 0.14736842105263157,
      "grad_norm": 1.7535184621810913,
      "learning_rate": 3.882105263157895e-05,
      "loss": 2.8507,
      "step": 210
    },
    {
      "epoch": 0.1543859649122807,
      "grad_norm": 1.8440556526184082,
      "learning_rate": 3.876491228070176e-05,
      "loss": 2.845,
      "step": 220
    },
    {
      "epoch": 0.16140350877192983,
      "grad_norm": 2.739072322845459,
      "learning_rate": 3.870877192982457e-05,
      "loss": 2.7908,
      "step": 230
    },
    {
      "epoch": 0.16842105263157894,
      "grad_norm": 2.2442898750305176,
      "learning_rate": 3.865263157894737e-05,
      "loss": 2.8799,
      "step": 240
    },
    {
      "epoch": 0.17543859649122806,
      "grad_norm": 1.558708906173706,
      "learning_rate": 3.859649122807018e-05,
      "loss": 2.8199,
      "step": 250
    },
    {
      "epoch": 0.1824561403508772,
      "grad_norm": 2.080963611602783,
      "learning_rate": 3.854035087719298e-05,
      "loss": 2.8463,
      "step": 260
    },
    {
      "epoch": 0.18947368421052632,
      "grad_norm": 1.878458023071289,
      "learning_rate": 3.848421052631579e-05,
      "loss": 2.7909,
      "step": 270
    },
    {
      "epoch": 0.19649122807017544,
      "grad_norm": 2.703425884246826,
      "learning_rate": 3.84280701754386e-05,
      "loss": 2.8115,
      "step": 280
    },
    {
      "epoch": 0.20350877192982456,
      "grad_norm": 2.2161977291107178,
      "learning_rate": 3.8371929824561404e-05,
      "loss": 2.8731,
      "step": 290
    },
    {
      "epoch": 0.21052631578947367,
      "grad_norm": 1.74897038936615,
      "learning_rate": 3.8315789473684216e-05,
      "loss": 2.8434,
      "step": 300
    },
    {
      "epoch": 0.21754385964912282,
      "grad_norm": 2.2848715782165527,
      "learning_rate": 3.825964912280702e-05,
      "loss": 2.8003,
      "step": 310
    },
    {
      "epoch": 0.22456140350877193,
      "grad_norm": 1.5549567937850952,
      "learning_rate": 3.820350877192983e-05,
      "loss": 2.7947,
      "step": 320
    },
    {
      "epoch": 0.23157894736842105,
      "grad_norm": 2.6425788402557373,
      "learning_rate": 3.814736842105264e-05,
      "loss": 2.8205,
      "step": 330
    },
    {
      "epoch": 0.23859649122807017,
      "grad_norm": 1.802551507949829,
      "learning_rate": 3.809122807017544e-05,
      "loss": 2.7145,
      "step": 340
    },
    {
      "epoch": 0.24561403508771928,
      "grad_norm": 2.1852502822875977,
      "learning_rate": 3.8035087719298247e-05,
      "loss": 2.8111,
      "step": 350
    },
    {
      "epoch": 0.25263157894736843,
      "grad_norm": 2.368276357650757,
      "learning_rate": 3.797894736842106e-05,
      "loss": 2.8463,
      "step": 360
    },
    {
      "epoch": 0.2596491228070175,
      "grad_norm": 2.226445198059082,
      "learning_rate": 3.792280701754386e-05,
      "loss": 2.9111,
      "step": 370
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 1.7844003438949585,
      "learning_rate": 3.786666666666667e-05,
      "loss": 2.7675,
      "step": 380
    },
    {
      "epoch": 0.2736842105263158,
      "grad_norm": 2.330906629562378,
      "learning_rate": 3.781052631578947e-05,
      "loss": 2.8501,
      "step": 390
    },
    {
      "epoch": 0.2807017543859649,
      "grad_norm": 2.0081257820129395,
      "learning_rate": 3.7754385964912284e-05,
      "loss": 2.832,
      "step": 400
    },
    {
      "epoch": 0.28771929824561404,
      "grad_norm": 2.00434947013855,
      "learning_rate": 3.769824561403509e-05,
      "loss": 2.8165,
      "step": 410
    },
    {
      "epoch": 0.29473684210526313,
      "grad_norm": 1.8228042125701904,
      "learning_rate": 3.76421052631579e-05,
      "loss": 2.8218,
      "step": 420
    },
    {
      "epoch": 0.3017543859649123,
      "grad_norm": 2.1645519733428955,
      "learning_rate": 3.7585964912280705e-05,
      "loss": 2.7658,
      "step": 430
    },
    {
      "epoch": 0.3087719298245614,
      "grad_norm": 2.1925501823425293,
      "learning_rate": 3.752982456140352e-05,
      "loss": 2.7958,
      "step": 440
    },
    {
      "epoch": 0.3157894736842105,
      "grad_norm": 2.2661092281341553,
      "learning_rate": 3.747368421052632e-05,
      "loss": 2.7793,
      "step": 450
    },
    {
      "epoch": 0.32280701754385965,
      "grad_norm": 2.250624895095825,
      "learning_rate": 3.741754385964913e-05,
      "loss": 2.8316,
      "step": 460
    },
    {
      "epoch": 0.3298245614035088,
      "grad_norm": 2.080410957336426,
      "learning_rate": 3.736140350877193e-05,
      "loss": 2.7856,
      "step": 470
    },
    {
      "epoch": 0.3368421052631579,
      "grad_norm": 1.7985458374023438,
      "learning_rate": 3.7305263157894736e-05,
      "loss": 2.7606,
      "step": 480
    },
    {
      "epoch": 0.34385964912280703,
      "grad_norm": 2.2048001289367676,
      "learning_rate": 3.724912280701755e-05,
      "loss": 2.7462,
      "step": 490
    },
    {
      "epoch": 0.3508771929824561,
      "grad_norm": 2.1360793113708496,
      "learning_rate": 3.719298245614035e-05,
      "loss": 2.784,
      "step": 500
    },
    {
      "epoch": 0.35789473684210527,
      "grad_norm": 2.2884340286254883,
      "learning_rate": 3.713684210526316e-05,
      "loss": 2.732,
      "step": 510
    },
    {
      "epoch": 0.3649122807017544,
      "grad_norm": 2.053619384765625,
      "learning_rate": 3.708070175438597e-05,
      "loss": 2.7212,
      "step": 520
    },
    {
      "epoch": 0.3719298245614035,
      "grad_norm": 2.4182064533233643,
      "learning_rate": 3.7024561403508774e-05,
      "loss": 2.7451,
      "step": 530
    },
    {
      "epoch": 0.37894736842105264,
      "grad_norm": 3.0081398487091064,
      "learning_rate": 3.6968421052631586e-05,
      "loss": 2.6418,
      "step": 540
    },
    {
      "epoch": 0.38596491228070173,
      "grad_norm": 2.160547971725464,
      "learning_rate": 3.691228070175439e-05,
      "loss": 2.7656,
      "step": 550
    },
    {
      "epoch": 0.3929824561403509,
      "grad_norm": 1.9496092796325684,
      "learning_rate": 3.6856140350877195e-05,
      "loss": 2.7134,
      "step": 560
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.012284278869629,
      "learning_rate": 3.680000000000001e-05,
      "loss": 2.7416,
      "step": 570
    },
    {
      "epoch": 0.4070175438596491,
      "grad_norm": 2.2347826957702637,
      "learning_rate": 3.674385964912281e-05,
      "loss": 2.7713,
      "step": 580
    },
    {
      "epoch": 0.41403508771929826,
      "grad_norm": 2.124694585800171,
      "learning_rate": 3.6687719298245616e-05,
      "loss": 2.736,
      "step": 590
    },
    {
      "epoch": 0.42105263157894735,
      "grad_norm": 2.7977211475372314,
      "learning_rate": 3.663157894736842e-05,
      "loss": 2.7214,
      "step": 600
    },
    {
      "epoch": 0.4280701754385965,
      "grad_norm": 2.994447946548462,
      "learning_rate": 3.657543859649123e-05,
      "loss": 2.7129,
      "step": 610
    },
    {
      "epoch": 0.43508771929824563,
      "grad_norm": 1.8589369058609009,
      "learning_rate": 3.651929824561404e-05,
      "loss": 2.6292,
      "step": 620
    },
    {
      "epoch": 0.4421052631578947,
      "grad_norm": 2.6086878776550293,
      "learning_rate": 3.646315789473684e-05,
      "loss": 2.711,
      "step": 630
    },
    {
      "epoch": 0.44912280701754387,
      "grad_norm": 2.4385807514190674,
      "learning_rate": 3.640701754385965e-05,
      "loss": 2.7657,
      "step": 640
    },
    {
      "epoch": 0.45614035087719296,
      "grad_norm": 1.9509507417678833,
      "learning_rate": 3.635087719298246e-05,
      "loss": 2.6432,
      "step": 650
    },
    {
      "epoch": 0.4631578947368421,
      "grad_norm": 2.312866449356079,
      "learning_rate": 3.6294736842105264e-05,
      "loss": 2.5241,
      "step": 660
    },
    {
      "epoch": 0.47017543859649125,
      "grad_norm": 2.4003210067749023,
      "learning_rate": 3.6238596491228075e-05,
      "loss": 2.7032,
      "step": 670
    },
    {
      "epoch": 0.47719298245614034,
      "grad_norm": 2.3473784923553467,
      "learning_rate": 3.618245614035088e-05,
      "loss": 2.6075,
      "step": 680
    },
    {
      "epoch": 0.4842105263157895,
      "grad_norm": 2.4621615409851074,
      "learning_rate": 3.612631578947369e-05,
      "loss": 2.7459,
      "step": 690
    },
    {
      "epoch": 0.49122807017543857,
      "grad_norm": 2.4075381755828857,
      "learning_rate": 3.6070175438596497e-05,
      "loss": 2.5369,
      "step": 700
    },
    {
      "epoch": 0.4982456140350877,
      "grad_norm": 1.8976678848266602,
      "learning_rate": 3.60140350877193e-05,
      "loss": 2.653,
      "step": 710
    },
    {
      "epoch": 0.5052631578947369,
      "grad_norm": 2.1373486518859863,
      "learning_rate": 3.5957894736842106e-05,
      "loss": 2.6255,
      "step": 720
    },
    {
      "epoch": 0.512280701754386,
      "grad_norm": 2.804265260696411,
      "learning_rate": 3.590175438596491e-05,
      "loss": 2.6311,
      "step": 730
    },
    {
      "epoch": 0.519298245614035,
      "grad_norm": 3.347088575363159,
      "learning_rate": 3.584561403508772e-05,
      "loss": 2.5796,
      "step": 740
    },
    {
      "epoch": 0.5263157894736842,
      "grad_norm": 3.2459871768951416,
      "learning_rate": 3.578947368421053e-05,
      "loss": 2.612,
      "step": 750
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 2.4887938499450684,
      "learning_rate": 3.573333333333333e-05,
      "loss": 2.6504,
      "step": 760
    },
    {
      "epoch": 0.5403508771929825,
      "grad_norm": 3.0579938888549805,
      "learning_rate": 3.5677192982456144e-05,
      "loss": 2.6607,
      "step": 770
    },
    {
      "epoch": 0.5473684210526316,
      "grad_norm": 2.490828037261963,
      "learning_rate": 3.562105263157895e-05,
      "loss": 2.7033,
      "step": 780
    },
    {
      "epoch": 0.5543859649122806,
      "grad_norm": 2.008807420730591,
      "learning_rate": 3.556491228070176e-05,
      "loss": 2.7719,
      "step": 790
    },
    {
      "epoch": 0.5614035087719298,
      "grad_norm": 2.113839626312256,
      "learning_rate": 3.5508771929824565e-05,
      "loss": 2.6976,
      "step": 800
    },
    {
      "epoch": 0.5684210526315789,
      "grad_norm": 1.725063443183899,
      "learning_rate": 3.545263157894737e-05,
      "loss": 2.6096,
      "step": 810
    },
    {
      "epoch": 0.5754385964912281,
      "grad_norm": 2.627526044845581,
      "learning_rate": 3.539649122807018e-05,
      "loss": 2.644,
      "step": 820
    },
    {
      "epoch": 0.5824561403508772,
      "grad_norm": 2.834496259689331,
      "learning_rate": 3.5340350877192986e-05,
      "loss": 2.6244,
      "step": 830
    },
    {
      "epoch": 0.5894736842105263,
      "grad_norm": 2.663980007171631,
      "learning_rate": 3.528421052631579e-05,
      "loss": 2.6561,
      "step": 840
    },
    {
      "epoch": 0.5964912280701754,
      "grad_norm": 2.16851806640625,
      "learning_rate": 3.5228070175438596e-05,
      "loss": 2.7719,
      "step": 850
    },
    {
      "epoch": 0.6035087719298246,
      "grad_norm": 2.2657828330993652,
      "learning_rate": 3.517192982456141e-05,
      "loss": 2.6184,
      "step": 860
    },
    {
      "epoch": 0.6105263157894737,
      "grad_norm": 3.8279430866241455,
      "learning_rate": 3.511578947368421e-05,
      "loss": 2.5488,
      "step": 870
    },
    {
      "epoch": 0.6175438596491228,
      "grad_norm": 2.2188053131103516,
      "learning_rate": 3.505964912280702e-05,
      "loss": 2.7421,
      "step": 880
    },
    {
      "epoch": 0.624561403508772,
      "grad_norm": 3.396851062774658,
      "learning_rate": 3.500350877192983e-05,
      "loss": 2.6973,
      "step": 890
    },
    {
      "epoch": 0.631578947368421,
      "grad_norm": 2.3508105278015137,
      "learning_rate": 3.4947368421052634e-05,
      "loss": 2.6578,
      "step": 900
    },
    {
      "epoch": 0.6385964912280702,
      "grad_norm": 2.473639488220215,
      "learning_rate": 3.4891228070175445e-05,
      "loss": 2.7415,
      "step": 910
    },
    {
      "epoch": 0.6456140350877193,
      "grad_norm": 2.55133318901062,
      "learning_rate": 3.483508771929825e-05,
      "loss": 2.6536,
      "step": 920
    },
    {
      "epoch": 0.6526315789473685,
      "grad_norm": 2.5952935218811035,
      "learning_rate": 3.4778947368421055e-05,
      "loss": 2.6127,
      "step": 930
    },
    {
      "epoch": 0.6596491228070176,
      "grad_norm": 2.2811100482940674,
      "learning_rate": 3.472280701754386e-05,
      "loss": 2.5652,
      "step": 940
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 2.6754233837127686,
      "learning_rate": 3.466666666666667e-05,
      "loss": 2.6682,
      "step": 950
    },
    {
      "epoch": 0.6736842105263158,
      "grad_norm": 2.2592999935150146,
      "learning_rate": 3.4610526315789476e-05,
      "loss": 2.5958,
      "step": 960
    },
    {
      "epoch": 0.6807017543859649,
      "grad_norm": 2.110684871673584,
      "learning_rate": 3.455438596491228e-05,
      "loss": 2.6584,
      "step": 970
    },
    {
      "epoch": 0.6877192982456141,
      "grad_norm": 3.2575292587280273,
      "learning_rate": 3.4498245614035086e-05,
      "loss": 2.5861,
      "step": 980
    },
    {
      "epoch": 0.6947368421052632,
      "grad_norm": 2.5890519618988037,
      "learning_rate": 3.44421052631579e-05,
      "loss": 2.6398,
      "step": 990
    },
    {
      "epoch": 0.7017543859649122,
      "grad_norm": 2.7118802070617676,
      "learning_rate": 3.43859649122807e-05,
      "loss": 2.6392,
      "step": 1000
    },
    {
      "epoch": 0.7087719298245614,
      "grad_norm": 2.4427032470703125,
      "learning_rate": 3.4329824561403514e-05,
      "loss": 2.6997,
      "step": 1010
    },
    {
      "epoch": 0.7157894736842105,
      "grad_norm": 5.150656700134277,
      "learning_rate": 3.427368421052632e-05,
      "loss": 2.5541,
      "step": 1020
    },
    {
      "epoch": 0.7228070175438597,
      "grad_norm": 2.1586952209472656,
      "learning_rate": 3.421754385964913e-05,
      "loss": 2.5476,
      "step": 1030
    },
    {
      "epoch": 0.7298245614035088,
      "grad_norm": 2.615097999572754,
      "learning_rate": 3.4161403508771935e-05,
      "loss": 2.5683,
      "step": 1040
    },
    {
      "epoch": 0.7368421052631579,
      "grad_norm": 2.702409505844116,
      "learning_rate": 3.410526315789474e-05,
      "loss": 2.6038,
      "step": 1050
    },
    {
      "epoch": 0.743859649122807,
      "grad_norm": 4.925928592681885,
      "learning_rate": 3.4049122807017545e-05,
      "loss": 2.6016,
      "step": 1060
    },
    {
      "epoch": 0.7508771929824561,
      "grad_norm": 3.0463132858276367,
      "learning_rate": 3.3992982456140356e-05,
      "loss": 2.5698,
      "step": 1070
    },
    {
      "epoch": 0.7578947368421053,
      "grad_norm": 3.2607173919677734,
      "learning_rate": 3.393684210526316e-05,
      "loss": 2.5488,
      "step": 1080
    },
    {
      "epoch": 0.7649122807017544,
      "grad_norm": 4.5317792892456055,
      "learning_rate": 3.3880701754385966e-05,
      "loss": 2.5297,
      "step": 1090
    },
    {
      "epoch": 0.7719298245614035,
      "grad_norm": 3.968909502029419,
      "learning_rate": 3.382456140350877e-05,
      "loss": 2.6739,
      "step": 1100
    },
    {
      "epoch": 0.7789473684210526,
      "grad_norm": 2.962228536605835,
      "learning_rate": 3.376842105263158e-05,
      "loss": 2.5119,
      "step": 1110
    },
    {
      "epoch": 0.7859649122807018,
      "grad_norm": 2.5637850761413574,
      "learning_rate": 3.371228070175439e-05,
      "loss": 2.6663,
      "step": 1120
    },
    {
      "epoch": 0.7929824561403509,
      "grad_norm": 3.1981775760650635,
      "learning_rate": 3.36561403508772e-05,
      "loss": 2.5304,
      "step": 1130
    },
    {
      "epoch": 0.8,
      "grad_norm": 4.480305194854736,
      "learning_rate": 3.3600000000000004e-05,
      "loss": 2.5741,
      "step": 1140
    },
    {
      "epoch": 0.8070175438596491,
      "grad_norm": 2.4116127490997314,
      "learning_rate": 3.3543859649122815e-05,
      "loss": 2.4903,
      "step": 1150
    },
    {
      "epoch": 0.8140350877192982,
      "grad_norm": 3.944413900375366,
      "learning_rate": 3.348771929824562e-05,
      "loss": 2.5365,
      "step": 1160
    },
    {
      "epoch": 0.8210526315789474,
      "grad_norm": 4.275918960571289,
      "learning_rate": 3.3431578947368425e-05,
      "loss": 2.5737,
      "step": 1170
    },
    {
      "epoch": 0.8280701754385965,
      "grad_norm": 3.6713762283325195,
      "learning_rate": 3.337543859649123e-05,
      "loss": 2.5388,
      "step": 1180
    },
    {
      "epoch": 0.8350877192982457,
      "grad_norm": 2.3156754970550537,
      "learning_rate": 3.3319298245614034e-05,
      "loss": 2.4443,
      "step": 1190
    },
    {
      "epoch": 0.8421052631578947,
      "grad_norm": 3.9870316982269287,
      "learning_rate": 3.3263157894736846e-05,
      "loss": 2.6256,
      "step": 1200
    },
    {
      "epoch": 0.8491228070175438,
      "grad_norm": 3.9808921813964844,
      "learning_rate": 3.320701754385965e-05,
      "loss": 2.6013,
      "step": 1210
    },
    {
      "epoch": 0.856140350877193,
      "grad_norm": 3.728199005126953,
      "learning_rate": 3.3150877192982456e-05,
      "loss": 2.5283,
      "step": 1220
    },
    {
      "epoch": 0.8631578947368421,
      "grad_norm": 4.356791019439697,
      "learning_rate": 3.309473684210527e-05,
      "loss": 2.5084,
      "step": 1230
    },
    {
      "epoch": 0.8701754385964913,
      "grad_norm": 3.26163387298584,
      "learning_rate": 3.303859649122807e-05,
      "loss": 2.5304,
      "step": 1240
    },
    {
      "epoch": 0.8771929824561403,
      "grad_norm": 4.752171993255615,
      "learning_rate": 3.298245614035088e-05,
      "loss": 2.68,
      "step": 1250
    },
    {
      "epoch": 0.8842105263157894,
      "grad_norm": 3.594406843185425,
      "learning_rate": 3.292631578947369e-05,
      "loss": 2.5157,
      "step": 1260
    },
    {
      "epoch": 0.8912280701754386,
      "grad_norm": 4.665381908416748,
      "learning_rate": 3.287017543859649e-05,
      "loss": 2.5215,
      "step": 1270
    },
    {
      "epoch": 0.8982456140350877,
      "grad_norm": 3.9278173446655273,
      "learning_rate": 3.2814035087719305e-05,
      "loss": 2.5225,
      "step": 1280
    },
    {
      "epoch": 0.9052631578947369,
      "grad_norm": 4.352803707122803,
      "learning_rate": 3.275789473684211e-05,
      "loss": 2.5333,
      "step": 1290
    },
    {
      "epoch": 0.9122807017543859,
      "grad_norm": 3.2656311988830566,
      "learning_rate": 3.2701754385964915e-05,
      "loss": 2.4274,
      "step": 1300
    },
    {
      "epoch": 0.9192982456140351,
      "grad_norm": 4.750765800476074,
      "learning_rate": 3.264561403508772e-05,
      "loss": 2.5407,
      "step": 1310
    },
    {
      "epoch": 0.9263157894736842,
      "grad_norm": 4.201137065887451,
      "learning_rate": 3.258947368421053e-05,
      "loss": 2.4999,
      "step": 1320
    },
    {
      "epoch": 0.9333333333333333,
      "grad_norm": 4.61777400970459,
      "learning_rate": 3.2533333333333336e-05,
      "loss": 2.4864,
      "step": 1330
    },
    {
      "epoch": 0.9403508771929825,
      "grad_norm": 5.378518581390381,
      "learning_rate": 3.247719298245614e-05,
      "loss": 2.5005,
      "step": 1340
    },
    {
      "epoch": 0.9473684210526315,
      "grad_norm": 3.8440842628479004,
      "learning_rate": 3.2421052631578945e-05,
      "loss": 2.475,
      "step": 1350
    },
    {
      "epoch": 0.9543859649122807,
      "grad_norm": 2.9044268131256104,
      "learning_rate": 3.236491228070176e-05,
      "loss": 2.4692,
      "step": 1360
    },
    {
      "epoch": 0.9614035087719298,
      "grad_norm": 5.908802032470703,
      "learning_rate": 3.230877192982456e-05,
      "loss": 2.4603,
      "step": 1370
    },
    {
      "epoch": 0.968421052631579,
      "grad_norm": 8.3141508102417,
      "learning_rate": 3.2252631578947373e-05,
      "loss": 2.3701,
      "step": 1380
    },
    {
      "epoch": 0.9754385964912281,
      "grad_norm": 5.039294242858887,
      "learning_rate": 3.219649122807018e-05,
      "loss": 2.5616,
      "step": 1390
    },
    {
      "epoch": 0.9824561403508771,
      "grad_norm": 3.7861204147338867,
      "learning_rate": 3.214035087719299e-05,
      "loss": 2.5694,
      "step": 1400
    },
    {
      "epoch": 0.9894736842105263,
      "grad_norm": 3.851377487182617,
      "learning_rate": 3.2084210526315795e-05,
      "loss": 2.4802,
      "step": 1410
    },
    {
      "epoch": 0.9964912280701754,
      "grad_norm": 4.255686283111572,
      "learning_rate": 3.20280701754386e-05,
      "loss": 2.3554,
      "step": 1420
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.26252522593665,
      "eval_f1_C01": 0.0,
      "eval_f1_C02": 0.0,
      "eval_f1_C03": 0.0,
      "eval_f1_C04": 0.3417624521072797,
      "eval_f1_C05": 0.0,
      "eval_f1_C06": 0.0,
      "eval_f1_C07": 0.0,
      "eval_f1_C08": 0.0,
      "eval_f1_C09": 0.0,
      "eval_f1_C10": 0.0025575447570332483,
      "eval_f1_C11": 0.0,
      "eval_f1_C12": 0.0,
      "eval_f1_C13": 0.0,
      "eval_f1_C14": 0.5859689476710753,
      "eval_f1_C15": 0.0,
      "eval_f1_C16": 0.0,
      "eval_f1_C17": 0.0,
      "eval_f1_C18": 0.1437908496732026,
      "eval_f1_C19": 0.0,
      "eval_f1_C20": 0.0,
      "eval_f1_C21": 0.0,
      "eval_f1_C22": 0.0,
      "eval_f1_C23": 0.28856592540710907,
      "eval_f1_macro": 0.05924546607024782,
      "eval_loss": 2.452338933944702,
      "eval_precision_C01": 1.0,
      "eval_precision_C02": 1.0,
      "eval_precision_C03": 1.0,
      "eval_precision_C04": 0.2120174938201179,
      "eval_precision_C05": 1.0,
      "eval_precision_C06": 0.0,
      "eval_precision_C07": 1.0,
      "eval_precision_C08": 1.0,
      "eval_precision_C09": 1.0,
      "eval_precision_C10": 0.08333333333333333,
      "eval_precision_C11": 1.0,
      "eval_precision_C12": 1.0,
      "eval_precision_C13": 1.0,
      "eval_precision_C14": 0.4512843224092117,
      "eval_precision_C15": 1.0,
      "eval_precision_C16": 1.0,
      "eval_precision_C17": 1.0,
      "eval_precision_C18": 0.44,
      "eval_precision_C19": 1.0,
      "eval_precision_C20": 0.0,
      "eval_precision_C21": 1.0,
      "eval_precision_C22": 1.0,
      "eval_precision_C23": 0.2174716283979942,
      "eval_precision_global": 0.7567002946939416,
      "eval_recall_C01": 0.0,
      "eval_recall_C02": 0.0,
      "eval_recall_C03": 0.0,
      "eval_recall_C04": 0.8807266982622433,
      "eval_recall_C05": 0.0,
      "eval_recall_C06": 0.0,
      "eval_recall_C07": 0.0,
      "eval_recall_C08": 0.0,
      "eval_recall_C09": 0.0,
      "eval_recall_C10": 0.0012987012987012987,
      "eval_recall_C11": 0.0,
      "eval_recall_C12": 0.0,
      "eval_recall_C13": 0.0,
      "eval_recall_C14": 0.8352459016393443,
      "eval_recall_C15": 0.0,
      "eval_recall_C16": 0.0,
      "eval_recall_C17": 0.0,
      "eval_recall_C18": 0.0859375,
      "eval_recall_C19": 0.0,
      "eval_recall_C20": 0.0,
      "eval_recall_C21": 0.0,
      "eval_recall_C22": 0.0,
      "eval_recall_C23": 0.4287200832466181,
      "eval_recall_global": 0.09704038628030032,
      "eval_runtime": 153.8668,
      "eval_samples_per_second": 74.071,
      "eval_steps_per_second": 2.32,
      "step": 1425
    }
  ],
  "logging_steps": 10,
  "max_steps": 7125,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.2186970118486016e+16,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
