## üß† Strat√©gie d'entra√Ænement des mod√®les

Nous avons entra√Æn√© plusieurs mod√®les de classification :  **DistillBert**, **ModernBert**, et **Deberta-v3-base**,sur trois jeux de donn√©es : **HateSpeech**, **IMDB**, et **OHSUMED**, en comparant les performances avec et sans l'utilisation de **LoRA (Low-Rank Adaptation)**.

### üìä S√©paration des donn√©es
Chaque dataset a √©t√© divis√© comme suit :
- **80% pour l'entra√Ænement**
- **20% pour l'√©valuation**

Cette r√©partition assure un bon √©quilibre entre apprentissage et validation.

### ‚öôÔ∏è Param√®tres d'entra√Ænement communs
Les entra√Ænements ont √©t√© r√©alis√©s avec les configurations suivantes :
- **Optimiseur** : AdamW
- **Scheduler** : Linear ou Cosine selon les cas
- **Learning Rate** : adapt√© pour chaque mod√®le
- **Weight Decay** : utilis√© pour la r√©gularisation
- **Nombre d‚Äô√©poques** : d√©termin√© pour chaque jeu de donn√©es en fonction de la convergence
- **Gradient Accumulation Steps** : utilis√© pour simuler de plus grands batchs
- **Tokenizer** : `distilbert-base-uncased` (pour les mod√®les DistilBERT), `deberta-v3-base` (pour le mod√®le deberta-v3-base)

### üîí Fine-tuning sans LoRA
Pour les versions **sans LoRA**, une approche de fine-tuning partiel a √©t√© utilis√©e :
- **Toutes les couches du mod√®le ont √©t√© gel√©es**, √† l'exception **des deux derni√®res couches**.
- Cette m√©thode permet de r√©duire le temps d'entra√Ænement et la consommation de ressources tout en maintenant une capacit√© d‚Äôadaptation.

### üß© Entra√Ænement avec LoRA
Dans les versions **avec LoRA**, nous avons utilis√© un entra√Ænement avec adaptation √† faible-rang pour am√©liorer l'efficacit√© et la performance tout en utilisant moins de ressources et de temps de calcul.

### üóÇÔ∏è HateSpeech

| **M√©thode**     | **Mod√®le**              | **Accuracy** | **F1 (macro)** | **Precision** | **Recall** | **Loss** | **Epochs** | **Batch (train/eval)** | **LR**   | **Weight Decay** | **LoRA Config**            | **Tokenizer**              | **Temps/√©poque (s)** | **CO‚ÇÇ (kg)** | **Grad Acc Steps** | **Warmup Steps** | **Scheduler** | **Max Grad Norm** | **Seed** | **GPU** |
|------------------|--------------------------|--------------|----------------|---------------|-------------|-----------|-------------|-------------------------|----------|------------------|----------------------------|-----------------------------|----------------------|--------------|--------------------|------------------|----------------|-------------------|----------|----------|
| Avec LoRA        | distilbert-base-uncased  | 0.9054       | 0.5807         | 0.8878        | 0.5441      | 0.3171    | 3           | 8 / 8                   | 5e-05    | 0.01             | r=8, Œ±=16, dropout=0.1     | distilbert-base-uncased    | 225.9512             | 0.0010       | -                  | -                | -              | -                 | -        | T4       |
| Sans LoRA        | distilbert-base-uncased  | 0.9054       | 0.5807         | 0.8878        | 0.5441      | 0.3171    | 3           | 8 / 8                   | 5e-05    | 0.01             | non utilis√©                | distilbert-base-uncased    | 225.9512             | 0.0010       | -                  | -                | -              | -                 | -        | T4       |
| Avec LoRA        | modern-bert              | 0.8597       | 0.2311         | 0.9649        | 0.25        | 0.4783    | 3           | 8 / 8                   | 5e-05    | 0.05             | r=8, Œ±=16, dropout=0.1     | modern-bert-base          | 1150.0000            | 0.0299       | 2                  | 2000             | LINEAR         | 1                 | 123      | T4       |
| Sans LoRA        | modern-bert              | 0.85746      | 0.2308         | 0.9643        | 0.25        | 0.4977    | 3           | 8 / 8                   | 5e-05    | 0.05             | non utilis√©                | modern-bert-base          | 1400.0000            | 0.0236       | 2                  | 2000             | LINEAR         | 1                 | 123      | T4       |
| Avec LoRA        | deberta-v3-base           | 0.8913       | 0.3718         | 0.8808        | 0.3654      | 0.3820    | 3           | 8 / 8                   | 5e-05    | 0.01             | r=8, Œ±=16, dropout=0.1     | deberta-v3-base           | 468.1251             | 0.0071       | -                  | -                | -              | -                 | -        | T4       |
| Sans LoRA        | deberta-v3-base           | 0.9018       | 0.5673         | 0.8519        | 0.5406      | 0.3417    | 3           | 8 / 8                   | 5e-05    | 0.01             | non utilis√©                | deberta-v3-base           | 252.1042             | 0.0037       | -                  | -                | -              | -                 | -        | T4       |

### üóÇÔ∏è IMDB

| **M√©thode**     | **Mod√®le**              | **Accuracy** | **F1 (macro)** | **Precision** | **Recall** | **Loss** | **Epochs** | **Batch (train/eval)** | **LR**   | **Weight Decay** | **LoRA Config**            | **Tokenizer**              | **Temps/√©poque (s)** | **CO‚ÇÇ (kg)** | **Grad Acc Steps** | **Warmup Steps** | **Scheduler** | **Max Grad Norm** | **Seed** | **GPU** |
|------------------|--------------------------|--------------|----------------|---------------|-------------|-----------|-------------|-------------------------|----------|------------------|----------------------------|-----------------------------|----------------------|--------------|--------------------|------------------|----------------|-------------------|----------|----------|
| Avec LoRA        | distilbert-base-uncased  | 0.9026       | 0.9026         | 0.9026        | 0.9027      | 0.2434    | 5           | 32 / 32                 | 3e-05    | 0.05             | r=8, Œ±=16, dropout=0.1     | distilbert-base-uncased    | 1136.7510            | 0.0104       | 2                  | 1000             | COSINE         | 0.8               | 123      | T4       |
| Sans LoRA        | distilbert-base-uncased  | 0.9230       | 0.9230         | 0.9230        | 0.9230      | 0.1996    | 5           | 32 / 32                 | 3e-05    | 0.05             | non utilis√©                | distilbert-base-uncased    | 733.0113             | 0.0067       | 2                  | 1000             | COSINE         | 0.8               | 123      | T4       |
| Avec LoRA        | modern-bert              | 0.8344       | 0.8394         | 0.8361        | 0.0346      | 0.3895    | 5           | 8 / 8                   | 5e-05    | 0.05             | r=8, Œ±=16, dropout=0.1     | modern-bert-base          | 608.4                | -            | 2                  | 2000             | LINEAR         | 1                 | 123      | T4       |
| Sans LoRA        | modern-bert              | 0.8484       | 0.8482         | 0.8485        | 0.8481      | 1.001     | 5           | 8 / 8                   | 5e-05    | 0.05             | non utilis√©                | modern-bert-base          | 1005.8               | 0.1183       | 2                  | 2000             | LINEAR         | 1                 | 123      | T4       |
| Avec LoRA        | deberta-v3-base           | 0.9354       | 0.9354         | 0.9354        | 0.9354      | 0.2160    | 1           | 8 / 8                   | 5e-05    | 0.01             | r=8, Œ±=16, dropout=0.1     | deberta-v3-base           | 1220.1435            | 0.0138       | -                  | -                | -              | -                 | -        | T4       |
| Sans LoRA        | deberta-v3-base           | 0.9412       | 0.9412         | 0.9413        | 0.9411      | 0.1846    | 1           | 8 / 8                   | 5e-05    | 0.01             | non utilis√©                | deberta-v3-base           | 709.3585             | 0.0080       | -                  | -                | -              | -                 | -        | T4       |

### üóÇÔ∏è OHSUMED

| **M√©thode**     | **Mod√®le**              | **Accuracy** | **F1 (macro)** | **Precision** | **Recall** | **Loss** | **Epochs** | **Batch (train/eval)** | **LR**   | **Weight Decay** | **LoRA Config**            | **Tokenizer**              | **Temps/√©poque (s)** | **CO‚ÇÇ (kg)** | **Grad Acc Steps** | **Warmup Steps** | **Scheduler** | **Max Grad Norm** | **Seed** | **GPU** |
|------------------|--------------------------|--------------|----------------|---------------|-------------|-----------|-------------|-------------------------|----------|------------------|----------------------------|-----------------------------|----------------------|--------------|--------------------|------------------|----------------|-------------------|----------|----------|
| Avec LoRA        | distilbert-base-uncased  | 0.4727       | 0.4385         | 0.4402        | 0.4558      | 1.5091    | 3           | 8 / 8                   | 5e-05    | 0.01             | r=8, Œ±=16, dropout=0.1     | distilbert-base-uncased    | 1312.6677            | 0.0147       | -                  | -                | -              | -                 | -        | T4       |
| Sans LoRA        | distilbert-base-uncased  | 0.4702       | 0.4367         | 0.4348        | 0.4507      | 1.5054    | 3           | 8 / 8                   | 5e-05    | 0.01             | non utilis√©                | distilbert-base-uncased    | 1229.2075            | 0.0184       | -                  | -                | -              | -                 | -        | T4       |
| Avec LoRA        | modern-bert              | 0.2882       | 0.2251         | 0.2185        | 0.2322      | 2.441     | 3           | 8 / 8                   | 5e-05    | 0.05             | r=8, Œ±=16, dropout=0.1     | modern-bert-base          | 2247.67              | 0.021        | 2                  | 2000             | LINEAR         | 1                 | 123      | T4       |
| Sans LoRA        | modern-bert              | 0.3205       | 0.1615         | 0.6308        | 0.1685      | 2.3340    | 3           | 8 / 8                   | 5e-05    | 0.05             | non utilis√©                | modern-bert-base          | 2205.67              | 0.0210       | 2                  | 2000             | LINEAR         | 1                 | 123      | T4       |
| Avec LoRA        | deberta-v3-base          | 0.4292       | 0.2979         | 0.4432        | 0.3316      | 1.8616    | 5           | 8 / 8                   | 5e-05    | 0.01             | r=8, Œ±=16, dropout=0.15    | deberta-v3-base            | 7204.8530            | 0.0858       | -                  | -                | -              | -                 | -        | T4       |
| Sans LoRA        | deberta-v3-base          | 0.4299       | 0.2889         | 0.4452        | 0.3476      | 1.8514    | 5           | 8 / 8                   | 5e-05    | 0.01             | non utilis√©                | deberta-v3-base            | 7154.5678            | 0.878        | -                  | -                | -              | -                 | -        | T4       |

Les r√©sultats obtenus par nos entra√Ænements sont coh√©rents avec les ressources que nous avons pu trouver, par exemple cet [article d‚ÄôHugging Face](https://huggingface.co/blog/modernbert) qui pr√©sente des m√©triques pour les mod√®les DeBERTa et ModernBERT.

Nous pouvons observer les diff√©rences entre nos √©valuations et d'autres r√©alis√©es sur le dataset IMDb via cette page : [Papers with Code ‚Äì Sentiment Analysis on IMDb](https://paperswithcode.com/sota/sentiment-analysis-on-imdb).

De m√™me, pour le dataset Ohsumed, des comparaisons sont possibles ici : [Papers with Code ‚Äì Text Classification on Ohsumed](https://paperswithcode.com/sota/text-classification-on-ohsumed).

üóÇÔ∏è T√¢che de Retrieval

## üìå Objectif
√âvaluer et comparer diff√©rents mod√®les de **sentence embedding** pour la t√¢che de retrieval de documents (recherche d'information) sur diff√©rents corpus :

## mod√®les sentences embeddings 


## üóÇÔ∏è Corpus
- **Quora**
- **NFCorpus**

**Fonctions principales** :
- Cr√©ation/sauvegarde/chargment embeddings
- Similarit√© cosinus sur les embeddings
- Utilisation de `pytrec_eval` pour l'√©valuation

## M√©triques d'√©valuation
- nDCG@100 : Pertinence des r√©sultats en tenant compte de leur position
- MAP@100 : Pr√©cision moyenne sur les 100 premiers r√©sultats

## R√©sultats
| # | Mod√®le           | Quora nDCG@100 | Quora MAP@100 | NFCorpus nDCG@100 | NFCorpus MAP@100 |
|---|------------------|----------------|---------------|-------------------|------------------|
| 1 | gte-modernbert   | 0.8832         | 0.8354        | 0.2728            | 0.1361           |
| 2 | distilbert-cos   | 0.8920         | 0.8477        | 0.2297            | 0.1084           |
| 3 | deberta-st       | 0.3217         | 0.2696        | 0.0202            | 0.0024           |



